# app/services/openai_service.py - –û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—Å–µ–π –±–∞–∑—ã
import httpx
from typing import List, Dict, Any
from app.config import settings
from app.models.car import Car
import logging
import asyncio

logger = logging.getLogger(__name__)


class OpenAIService:
    def __init__(self):
        self.api_key = settings.openai_api_key
        self.base_url = "https://api.openai.com/v1"

    async def analyze_full_market(self, all_cars: List[Car], brands_stats: Dict[str, List[Car]]) -> Dict[str, Any]:
        """üéØ –ì–õ–ê–í–ù–´–ô –ú–ï–¢–û–î: –ê–Ω–∞–ª–∏–∑ –≤—Å–µ–≥–æ —Ä—ã–Ω–∫–∞ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º"""

        if not all_cars:
            return {"error": "–ù–µ—Ç –º–∞—à–∏–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", "total_cars_analyzed": 0}

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        market_summary = self._prepare_market_summary(all_cars, brands_stats)
        input_text = self._build_full_market_analysis_input(market_summary,
                                                            all_cars[:50])  # –¢–æ–ø-50 –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞

        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/responses",
                    headers={
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {self.api_key}"
                    },
                    json={
                        "model": "o3-mini",
                        "input": input_text
                    },
                    timeout=120.0  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º timeout –¥–ª—è –±–æ–ª—å—à–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                )

                if response.status_code != 200:
                    raise Exception(f"API Error {response.status_code}: {response.text}")

                result = response.json()
                analysis_text = self._extract_response_text(result)

                return self._parse_full_market_analysis(analysis_text, all_cars, brands_stats)

        except Exception as e:
            logger.error(f"‚ùå Full market analysis error: {e}")
            raise Exception(f"–û—à–∏–±–∫–∞ AI –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–∞: {str(e)}")

    async def analyze_market_trends(self, all_cars: List[Car], recent_cars: List[Car], days: int) -> Dict[str, Any]:
        """üìà –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ —Ä—ã–Ω–∫–∞"""

        trends_data = self._prepare_trends_data(all_cars, recent_cars, days)
        input_text = self._build_trends_analysis_input(trends_data)

        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/responses",
                    headers={
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {self.api_key}"
                    },
                    json={
                        "model": "o3-mini",
                        "input": input_text
                    },
                    timeout=90.0
                )

                if response.status_code == 200:
                    result = response.json()
                    analysis_text = self._extract_response_text(result)
                    return self._parse_trends_analysis(analysis_text, all_cars, recent_cars)
                else:
                    raise Exception(f"API Error {response.status_code}")

        except Exception as e:
            logger.error(f"‚ùå Trends analysis error: {e}")
            raise Exception(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤: {str(e)}")

    def _prepare_market_summary(self, all_cars: List[Car], brands_stats: Dict[str, List[Car]]) -> Dict[str, Any]:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ —Ä—ã–Ω–∫—É"""

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_cars = len(all_cars)
        years = [car.year for car in all_cars if car.year]
        mileages = [car.mileage for car in all_cars if car.mileage]

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—ã
        prices = []
        for car in all_cars:
            if car.price:
                price_clean = car.price.replace('‚Ç¨', '').replace(',', '').replace(' ', '').strip()
                try:
                    if price_clean.isdigit():
                        prices.append(int(price_clean))
                except:
                    pass

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –±—Ä–µ–Ω–¥–∞–º
        brands_summary = {}
        for brand, cars in brands_stats.items():
            brands_summary[brand] = {
                "count": len(cars),
                "avg_year": sum(car.year for car in cars if car.year) / len([car for car in cars if car.year]) if any(
                    car.year for car in cars) else None,
                "avg_mileage": sum(car.mileage for car in cars if car.mileage) / len(
                    [car for car in cars if car.mileage]) if any(car.mileage for car in cars) else None
            }

        return {
            "total_cars": total_cars,
            "avg_year": sum(years) / len(years) if years else None,
            "year_range": f"{min(years)}-{max(years)}" if years else None,
            "avg_mileage": sum(mileages) / len(mileages) if mileages else None,
            "mileage_range": f"{min(mileages):,}-{max(mileages):,}" if mileages else None,
            "avg_price": sum(prices) / len(prices) if prices else None,
            "price_range": f"‚Ç¨{min(prices):,}-‚Ç¨{max(prices):,}" if prices else None,
            "brands_count": len(brands_stats),
            "brands_summary": brands_summary,
            "top_3_brands": sorted(brands_stats.items(), key=lambda x: len(x[1]), reverse=True)[:3]
        }

    def _prepare_trends_data(self, all_cars: List[Car], recent_cars: List[Car], days: int) -> Dict[str, Any]:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤"""

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º recent_cars –ø–æ –¥–Ω—è–º
        from collections import defaultdict
        daily_activity = defaultdict(int)

        for car in recent_cars:
            if car.created_at:
                date_str = car.created_at.strftime('%Y-%m-%d')
                daily_activity[date_str] += 1

        # –°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        avg_daily = len(recent_cars) / days if days > 0 else 0

        return {
            "total_in_db": len(all_cars),
            "recent_additions": len(recent_cars),
            "analysis_period": days,
            "avg_daily_additions": round(avg_daily, 1),
            "daily_breakdown": dict(daily_activity),
            "recent_vs_total_ratio": round(len(recent_cars) / len(all_cars) * 100, 1) if all_cars else 0
        }

    def _build_full_market_analysis_input(self, market_summary: Dict[str, Any], sample_cars: List[Car]) -> str:
        """–°—Ç—Ä–æ–∏—Ç input –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–∞"""

        system_context = """–¢—ã –æ–ø—ã—Ç–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–≥–æ —Ä—ã–Ω–∫–∞ –ö–∏–ø—Ä–∞ —Å 15-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º.

–¢–í–û–Ø –ó–ê–î–ê–ß–ê: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –í–ï–°–¨ —Ä—ã–Ω–æ–∫ –ø–æ–¥–µ—Ä–∂–∞–Ω–Ω—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π –Ω–∞ –ö–∏–ø—Ä–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.

–û–°–û–ë–ï–ù–ù–û–°–¢–ò –†–´–ù–ö–ê –ö–ò–ü–†–ê:
- –í—ã—Å–æ–∫–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã (–≤–ª–∏—è–Ω–∏–µ –Ω–∞ –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä—ã, —Ä–µ–∑–∏–Ω—É, –ø–ª–∞—Å—Ç–∏–∫)
- –ú–æ—Ä—Å–∫–∞—è —Å–æ–ª—å (–∫–æ—Ä—Ä–æ–∑–∏—è)  
- –ú–∞–ª—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è (–Ω–∏–∑–∫–∏–π –ø—Ä–æ–±–µ–≥ –Ω–µ –≤—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å)
- –î–æ—Ä–æ–≥–∏–µ –∑–∞–ø—á–∞—Å—Ç–∏ –∏ —Å–µ—Ä–≤–∏—Å
- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π

–ê–ù–ê–õ–ò–ó –û–ü–ò–°–ê–ù–ò–ô - –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
- –ò—â–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å—Ä–æ—á–Ω–æ–π –ø—Ä–æ–¥–∞–∂–∏ ("—Å—Ä–æ—á–Ω–æ", "urgent", "–ø–µ—Ä–µ–µ–∑–¥", "—Å–Ω–∏–∂–µ–Ω–∞ —Ü–µ–Ω–∞")
- –û–±—Ä–∞—â–∞–π –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–µ ("–æ—Ç–ª–∏—á–Ω–æ–µ", "–∏–¥–µ–∞–ª—å–Ω–æ–µ", "—Ç—Ä–µ–±—É–µ—Ç —Ä–µ–º–æ–Ω—Ç–∞")
- –ò—â–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Å–µ—Ä–≤–∏—Å–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏ ("—Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –¢–û", "—Ç–æ–ª—å–∫–æ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å")
- –û—Ç–º–µ—á–∞–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
- –í—ã—è–≤–ª—è–π —Å–∫—Ä—ã—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã ("—Ç–æ—Ä–≥ —É–º–µ—Å—Ç–µ–Ω", "–Ω–µ–±–æ–ª—å—à–∏–µ —Ü–∞—Ä–∞–ø–∏–Ω—ã", "–∫–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–º–æ–Ω—Ç")

–ü–†–ò–ù–¶–ò–ü–´ –ê–ù–ê–õ–ò–ó–ê:
- –ß–µ—Å—Ç–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞–π —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ä—ã–Ω–∫–∞
- –í—ã–¥–µ–ª—è–π –ª—É—á—à–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—é —Ü–µ–Ω–∞/–∫–∞—á–µ—Å—Ç–≤–æ
- –£—á–∏—Ç—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –æ–ø–∏—Å–∞–Ω–∏–π –¥–ª—è —Ç–æ—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
- –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–π –æ –∑–∞–≤—ã—à–µ–Ω–Ω—ã—Ö —Ü–µ–Ω–∞—Ö –∏ —Å–∫—Ä—ã—Ç—ã—Ö –ø—Ä–æ–±–ª–µ–º–∞—Ö
- –†–µ–∫–æ–º–µ–Ω–¥—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –º–∞—à–∏–Ω—ã –ø–æ ID"""

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–≤–æ–¥–∫—É –ø–æ —Ä—ã–Ω–∫—É
        brands_info = "\n".join([
            f"‚Ä¢ {brand}: {data['count']} –º–∞—à–∏–Ω, —Å—Ä–µ–¥–Ω–∏–π –≥–æ–¥: {data['avg_year']:.0f if data['avg_year'] else '–Ω/–¥'}, —Å—Ä–µ–¥–Ω–∏–π –ø—Ä–æ–±–µ–≥: {data['avg_mileage']:,.0f if data['avg_mileage'] else '–Ω/–¥'} –∫–º"
            for brand, data in market_summary["brands_summary"].items()
        ])

        # –ü—Ä–∏–º–µ—Ä—ã –º–∞—à–∏–Ω –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (—Ç–æ–ø-20)
        sample_cars_info = []
        for i, car in enumerate(sample_cars[:20], 1):
            price_clean = car.price.replace('‚Ç¨', '').replace(',', '').replace(' ', '').strip() if car.price else '–Ω/–¥'
            price_euro = f" ({int(price_clean):,} ‚Ç¨)" if price_clean.isdigit() else ""

            # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            description_text = ""
            if car.description and car.description.strip():
                desc_clean = car.description.strip()[:300]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏
                description_text = f"‚Ä¢ –û–ø–∏—Å–∞–Ω–∏–µ: {desc_clean}{'...' if len(car.description) > 300 else ''}"

            sample_cars_info.append(f"""
–ú–∞—à–∏–Ω–∞ #{i} (ID: {car.id}):
‚Ä¢ {car.title}
‚Ä¢ {car.brand} {car.year or '–Ω/–¥'} –≥–æ–¥–∞
‚Ä¢ –ü—Ä–æ–±–µ–≥: {f"{car.mileage:,} –∫–º" if car.mileage else '–Ω/–¥'}
‚Ä¢ –¶–µ–Ω–∞: {car.price}{price_euro}
‚Ä¢ –ú–µ—Å—Ç–æ: {car.place}
‚Ä¢ –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {(car.features or '–Ω/–¥')[:100]}
{description_text}
""")

        return f"""{system_context}

–ü–û–õ–ù–ê–Ø –°–í–û–î–ö–ê –ü–û –†–´–ù–ö–£:
üìä –í—Å–µ–≥–æ –º–∞—à–∏–Ω –≤ –±–∞–∑–µ: {market_summary["total_cars"]}
üìÖ –ì–æ–¥—ã –≤—ã–ø—É—Å–∫–∞: {market_summary["year_range"]}
üõ£ –ü—Ä–æ–±–µ–≥: {market_summary["mileage_range"]}
üí∞ –¶–µ–Ω—ã: {market_summary["price_range"]}
üè∑Ô∏è –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–æ –±—Ä–µ–Ω–¥–æ–≤: {market_summary["brands_count"]}

–†–ê–ó–ë–ò–í–ö–ê –ü–û –ë–†–ï–ù–î–ê–ú:
{brands_info}

–¢–û–ü-20 –ú–ê–®–ò–ù –î–õ–Ø –î–ï–¢–ê–õ–¨–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê:
{"".join(sample_cars_info)}

–ü–†–û–í–ï–î–ò –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ê–ù–ê–õ–ò–ó:

**–°–û–°–¢–û–Ø–ù–ò–ï –†–´–ù–ö–ê:**
–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ —Ä—ã–Ω–∫–∞, –¥–∏–Ω–∞–º–∏–∫–∞, –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã

**–ê–ù–ê–õ–ò–ó –ü–û –ë–†–ï–ù–î–ê–ú:**
–î–ª—è –∫–∞–∂–¥–æ–≥–æ –±—Ä–µ–Ω–¥–∞ –æ—Ü–µ–Ω–∏:
- –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ —Ä—ã–Ω–∫–µ
- –°—Ä–µ–¥–Ω–∏–µ —Ü–µ–Ω—ã –∏ –∏—Ö –∞–¥–µ–∫–≤–∞—Ç–Ω–æ—Å—Ç—å
- –¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –º–æ–¥–µ–ª–µ–π
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É

**–¢–û–ü-10 –õ–£–ß–®–ò–• –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ô:**
–í—ã–±–µ—Ä–∏ 10 –ª—É—á—à–∏—Ö –º–∞—à–∏–Ω –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º:
1. –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ü–µ–Ω–∞/–∫–∞—á–µ—Å—Ç–≤–æ
2. –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
3. –°–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –∫–ª–∏–º–∞—Ç–∞ –ö–∏–ø—Ä–∞
4. –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–∏—Å–∞ –∏ –∑–∞–ø—á–∞—Å—Ç–µ–π
5. –ê–ù–ê–õ–ò–ó –û–ü–ò–°–ê–ù–ò–ô (—Å—Ä–æ—á–Ω–æ—Å—Ç—å, —Å–æ—Å—Ç–æ—è–Ω–∏–µ, –∏—Å—Ç–æ—Ä–∏—è)

**–ê–ù–ê–õ–ò–ó –û–ü–ò–°–ê–ù–ò–ô:**
–î–ª—è –∫–∞–∂–¥–æ–π —Ç–æ–ø-–º–∞—à–∏–Ω—ã –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π:
- –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å—Ä–æ—á–Ω–æ–π –ø—Ä–æ–¥–∞–∂–∏ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
- –£–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –∏ —Å–µ—Ä–≤–∏—Å–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏
- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è
- –í–æ–∑–º–æ–∂–Ω—ã–µ —Å–∫—Ä—ã—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –≤ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞—Ö

**–û–ë–©–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:**
–°–æ–≤–µ—Ç—ã –ø–æ–∫—É–ø–∞—Ç–µ–ª—è–º –ø–æ —Ç–µ–∫—É—â–µ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é —Ä—ã–Ω–∫–∞

–£–∫–∞–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ ID –º–∞—à–∏–Ω –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö!"""

    def _build_trends_analysis_input(self, trends_data: Dict[str, Any]) -> str:
        """–°—Ç—Ä–æ–∏—Ç input –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤"""

        daily_info = "\n".join([
            f"‚Ä¢ {date}: {count} –º–∞—à–∏–Ω"
            for date, count in sorted(trends_data["daily_breakdown"].items(), reverse=True)[:10]
        ])

        return f"""–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–≥–æ —Ä—ã–Ω–∫–∞ –ö–∏–ø—Ä–∞. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç—Ä–µ–Ω–¥—ã –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏:

–î–ê–ù–ù–´–ï –ó–ê –ü–û–°–õ–ï–î–ù–ò–ï {trends_data["analysis_period"]} –î–ù–ï–ô:
üìä –í—Å–µ–≥–æ –≤ –±–∞–∑–µ: {trends_data["total_in_db"]} –º–∞—à–∏–Ω
üìà –ù–æ–≤—ã—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥: {trends_data["recent_additions"]} –º–∞—à–∏–Ω  
‚ö° –°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {trends_data["avg_daily_additions"]} –º–∞—à–∏–Ω/–¥–µ–Ω—å
üìä –î–æ–ª—è –Ω–æ–≤—ã—Ö: {trends_data["recent_vs_total_ratio"]}%

–ê–ö–¢–ò–í–ù–û–°–¢–¨ –ü–û –î–ù–Ø–ú (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10):
{daily_info}

–ê–ù–ê–õ–ò–ó–ò–†–£–ô:
**–î–ò–ù–ê–ú–ò–ö–ê –†–´–ù–ö–ê:**
- –†–∞—Å—Ç–µ—Ç –∏–ª–∏ –ø–∞–¥–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å?
- –ï—Å—Ç—å –ª–∏ —Å–µ–∑–æ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã?
- –û—Ü–µ–Ω–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Ä—ã–Ω–∫–∞

**–¢–†–ï–ù–î–´ –¶–ï–ù:**
- –î–≤–∏–∂–µ–Ω–∏–µ —Ü–µ–Ω –≤–≤–µ—Ä—Ö/–≤–Ω–∏–∑
- –í–ª–∏—è–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–∞ —Ü–µ–Ω—ã

**–ü–†–û–ì–ù–û–ó:**
- –û–∂–∏–¥–∞–Ω–∏—è –Ω–∞ –±–ª–∏–∂–∞–π—à–∏–µ –Ω–µ–¥–µ–ª–∏
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ–∫—É–ø–∫–∏

**–í–´–í–û–î–´:**
–ö—Ä–∞—Ç–∫–∏–µ –≤—ã–≤–æ–¥—ã –¥–ª—è –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π"""

    def _parse_full_market_analysis(self, analysis_text: str, all_cars: List[Car], brands_stats: Dict) -> Dict[
        str, Any]:
        """–ü–∞—Ä—Å–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–∞"""

        if not isinstance(analysis_text, str):
            analysis_text = str(analysis_text)

        sections = analysis_text.split("**")

        market_overview = ""
        brand_analysis = ""
        top_recommendations = ""
        general_conclusions = ""

        for i, section in enumerate(sections):
            section_lower = section.lower()
            if "—Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ä—ã–Ω–∫–∞" in section_lower or "market" in section_lower:
                market_overview = sections[i + 1] if i + 1 < len(sections) else ""
            elif "–∞–Ω–∞–ª–∏–∑ –ø–æ –±—Ä–µ–Ω–¥–∞–º" in section_lower or "brands" in section_lower:
                brand_analysis = sections[i + 1] if i + 1 < len(sections) else ""
            elif "–ª—É—á—à–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π" in section_lower or "—Ç–æ–ø" in section_lower or "top" in section_lower:
                top_recommendations = sections[i + 1] if i + 1 < len(sections) else ""
            elif "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏" in section_lower or "–≤—ã–≤–æ–¥—ã" in section_lower:
                general_conclusions = sections[i + 1] if i + 1 < len(sections) else ""

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ ID
        recommended_ids = self._extract_recommended_car_ids(top_recommendations, all_cars)

        return {
            "total_cars_analyzed": len(all_cars),
            "market_overview": market_overview.strip(),
            "brand_analysis": brand_analysis.strip(),
            "top_recommendations": top_recommendations.strip(),
            "general_conclusions": general_conclusions.strip(),
            "full_analysis": analysis_text,
            "recommended_car_ids": recommended_ids,
            "model_used": "o3-mini",
            "api_version": "responses_v1",
            "brands_analyzed": list(brands_stats.keys()),
            "cars_data": [
                {
                    "id": car.id,
                    "title": car.title,
                    "brand": car.brand,
                    "year": car.year,
                    "price": car.price,
                    "mileage": car.mileage,
                    "link": car.link,
                    "description": car.description[:200] + "..." if car.description and len(
                        car.description) > 200 else car.description
                } for car in all_cars[:100]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞ –æ—Ç–≤–µ—Ç–∞
            ]
        }

    def _parse_trends_analysis(self, analysis_text: str, all_cars: List[Car], recent_cars: List[Car]) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤"""

        sections = analysis_text.split("**")

        market_dynamics = ""
        price_trends = ""
        forecast = ""
        conclusions = ""

        for i, section in enumerate(sections):
            section_lower = section.lower()
            if "–¥–∏–Ω–∞–º–∏–∫–∞" in section_lower:
                market_dynamics = sections[i + 1] if i + 1 < len(sections) else ""
            elif "—Ç—Ä–µ–Ω–¥—ã —Ü–µ–Ω" in section_lower or "price" in section_lower:
                price_trends = sections[i + 1] if i + 1 < len(sections) else ""
            elif "–ø—Ä–æ–≥–Ω–æ–∑" in section_lower:
                forecast = sections[i + 1] if i + 1 < len(sections) else ""
            elif "–≤—ã–≤–æ–¥—ã" in section_lower:
                conclusions = sections[i + 1] if i + 1 < len(sections) else ""

        return {
            "total_cars_analyzed": len(all_cars),
            "recent_cars_count": len(recent_cars),
            "market_dynamics": market_dynamics.strip(),
            "price_trends": price_trends.strip(),
            "forecast": forecast.strip(),
            "conclusions": conclusions.strip(),
            "full_analysis": analysis_text,
            "model_used": "o3-mini"
        }

    # LEGACY –º–µ—Ç–æ–¥—ã –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    async def analyze_cars(self, cars: List[Car]) -> Dict[str, Any]:
        """Legacy –º–µ—Ç–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–ø–∏—Å–∫–∞ –º–∞—à–∏–Ω"""
        if not cars:
            return {"error": "–ù–µ—Ç –º–∞—à–∏–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", "total_cars_analyzed": 0}

        cars_data = self._prepare_cars_data(cars)
        input_text = self._build_analysis_input(cars_data)

        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/responses",
                    headers={
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {self.api_key}"
                    },
                    json={
                        "model": "o3-mini",
                        "input": input_text
                    },
                    timeout=60.0
                )

                if response.status_code != 200:
                    raise Exception(f"API Error {response.status_code}: {response.text}")

                result = response.json()
                analysis_text = self._extract_response_text(result)
                return self._parse_analysis_response(analysis_text, cars)

        except Exception as e:
            logger.error(f"‚ùå Legacy analyze_cars error: {e}")
            raise Exception(f"–û—à–∏–±–∫–∞ AI –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")

    def _extract_response_text(self, api_response: Dict) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ API (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)"""
        try:
            logger.info(f"API Response structure: {list(api_response.keys())}")

            if "text" in api_response:
                text_value = api_response["text"]
                if isinstance(text_value, dict):
                    logger.info(f"Text dict content: {text_value}")
                else:
                    return str(text_value)

            if "output" in api_response:
                output = api_response["output"]
                if isinstance(output, list):
                    for i, output_item in enumerate(output):
                        if isinstance(output_item, dict):
                            item_type = output_item.get("type", "unknown")
                            if item_type == "message":
                                if "content" in output_item:
                                    content_array = output_item["content"]
                                    if isinstance(content_array, list) and len(content_array) > 0:
                                        for content_item in content_array:
                                            if isinstance(content_item, dict) and "text" in content_item:
                                                return str(content_item["text"])

            # Fallback - –∏—â–µ–º –ª—é–±—É—é –¥–ª–∏–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É
            def find_long_strings(obj, path=""):
                results = []
                if isinstance(obj, dict):
                    for key, value in obj.items():
                        new_path = f"{path}.{key}" if path else key
                        if isinstance(value, str) and len(value) > 50:
                            results.append((new_path, value))
                        else:
                            results.extend(find_long_strings(value, new_path))
                elif isinstance(obj, list):
                    for i, item in enumerate(obj):
                        new_path = f"{path}[{i}]"
                        results.extend(find_long_strings(item, new_path))
                return results

            long_strings = find_long_strings(api_response)
            if long_strings:
                return long_strings[0][1]

            return str(api_response)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {e}")
            return f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}"

    def _extract_recommended_car_ids(self, recommendations: str, cars: List[Car]) -> List[int]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç ID —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã—Ö –º–∞—à–∏–Ω"""
        import re

        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∏–ø–∞ "ID: 123", "–ú–∞—à–∏–Ω–∞ #1", "ID 456"
        id_patterns = [
            r'ID:\s*(\d+)',
            r'ID\s+(\d+)',
            r'–ú–∞—à–∏–Ω–∞\s+#(\d+)',
            r'\(ID:\s*(\d+)\)',
            r'–º–∞—à–∏–Ω[–∞—ã]\s+(\d+)',
            r'#(\d+)'
        ]

        found_ids = set()

        for pattern in id_patterns:
            matches = re.findall(pattern, recommendations, re.IGNORECASE)
            for match in matches:
                try:
                    car_id = int(match)
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç–∞–∫–æ–π ID —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –Ω–∞—à–µ–º —Å–ø–∏—Å–∫–µ
                    if any(car.id == car_id for car in cars):
                        found_ids.add(car_id)
                except ValueError:
                    continue

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ ID, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –Ω–æ–º–µ—Ä–∞ –º–∞—à–∏–Ω –∏–∑ –Ω—É–º–µ—Ä–∞—Ü–∏–∏
        if not found_ids:
            number_matches = re.findall(r'–ú–∞—à–∏–Ω–∞ #(\d+)', recommendations)
            for num_str in number_matches:
                try:
                    car_index = int(num_str) - 1
                    if 0 <= car_index < len(cars):
                        found_ids.add(cars[car_index].id)
                except (ValueError, IndexError):
                    continue

        return list(found_ids)

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    def _prepare_cars_data(self, cars: List[Car]) -> str:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –º–∞—à–∏–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (legacy)"""
        cars_info = []
        for i, car in enumerate(cars, 1):
            price_clean = car.price.replace('‚Ç¨', '').replace(',', '').replace(' ',
                                                                              '').strip() if car.price else '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'
            price_numeric = ""
            if price_clean.isdigit():
                price_numeric = f" ({int(price_clean):,} –µ–≤—Ä–æ)"

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ - –≤–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è AI
            description_text = ""
            if car.description and car.description.strip():
                desc_clean = car.description.strip()[:400]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 400 —Å–∏–º–≤–æ–ª–æ–≤
                description_text = f"‚Ä¢ –û–ø–∏—Å–∞–Ω–∏–µ: {desc_clean}{'...' if len(car.description) > 400 else ''}"

            info = f"""
–ê–≤—Ç–æ–º–æ–±–∏–ª—å #{i} (ID: {car.id}):
‚Ä¢ –ú–æ–¥–µ–ª—å: {car.title}
‚Ä¢ –ú–∞—Ä–∫–∞: {car.brand}
‚Ä¢ –ì–æ–¥ –≤—ã–ø—É—Å–∫–∞: {car.year or '–Ω–µ —É–∫–∞–∑–∞–Ω'}
‚Ä¢ –ü—Ä–æ–±–µ–≥: {f"{car.mileage:,} –∫–º" if car.mileage else '–Ω–µ —É–∫–∞–∑–∞–Ω'}
‚Ä¢ –¶–µ–Ω–∞: {car.price}{price_numeric}
‚Ä¢ –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {car.features[:250] if car.features else '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}
‚Ä¢ –ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ: {car.place}
{description_text}
"""
            cars_info.append(info)
        return "\n".join(cars_info)

    def _build_analysis_input(self, cars_data: str) -> str:
        """–°—Ç—Ä–æ–∏—Ç input –¥–ª—è legacy –∞–Ω–∞–ª–∏–∑–∞"""
        system_context = """–¢—ã –æ–ø—ã—Ç–Ω—ã–π –∞–≤—Ç–æ—ç–∫—Å–ø–µ—Ä—Ç —Å 20-–ª–µ—Ç–Ω–∏–º —Å—Ç–∞–∂–µ–º –Ω–∞ –µ–≤—Ä–æ–ø–µ–π—Å–∫–æ–º —Ä—ã–Ω–∫–µ –ø–æ–¥–µ—Ä–∂–∞–Ω–Ω—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π.

–¢–í–û–Ø –≠–ö–°–ü–ï–†–¢–ò–ó–ê:
- –ó–Ω–∞–Ω–∏–µ —Ç–∏–ø–∏—á–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ BMW, Mercedes, Audi, Volkswagen
- –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è –≤ –ï–≤—Ä–æ–ø–µ  
- –û—Ü–µ–Ω–∫–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Ü–µ–Ω–∞/–∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ä—ã–Ω–∫–µ –ö–∏–ø—Ä–∞
- –ü—Ä–æ–≥–Ω–æ–∑ –∏–∑–Ω–æ—Å–∞ –ø–æ –ø—Ä–æ–±–µ–≥—É –∏ –≥–æ–¥—É –≤—ã–ø—É—Å–∫–∞
- –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∫–ª–∏–º–∞—Ç–∞ –ö–∏–ø—Ä–∞ (–∂–∞—Ä–∞, —Å–æ–ª—å) –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏"""

        return f"""{system_context}

–ó–ê–î–ê–ß–ê: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏ –¥–ª—è –ø–æ–∫—É–ø–∫–∏ –Ω–∞ –ö–∏–ø—Ä–µ:

{cars_data}

–°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê:
**–¢–û–ü-3 –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:**
1. –ê–≤—Ç–æ–º–æ–±–∏–ª—å #X - –∫—Ä–∞—Ç–∫–∞—è –ø—Ä–∏—á–∏–Ω–∞
2. –ê–≤—Ç–æ–º–æ–±–∏–ª—å #Y - –∫—Ä–∞—Ç–∫–∞—è –ø—Ä–∏—á–∏–Ω–∞  
3. –ê–≤—Ç–æ–º–æ–±–∏–ª—å #Z - –∫—Ä–∞—Ç–∫–∞—è –ø—Ä–∏—á–∏–Ω–∞

**–î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó:**
–î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è –¥–∞–π –æ—Ü–µ–Ω–∫—É

**–û–ë–©–ò–ï –í–´–í–û–î–´:**
–ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""

    def _parse_analysis_response(self, analysis_text: str, cars: List[Car]) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç legacy –∞–Ω–∞–ª–∏–∑–∞"""
        if not isinstance(analysis_text, str):
            analysis_text = str(analysis_text)

        sections = analysis_text.split("**")
        top_recommendations = ""
        detailed_analysis = ""
        general_conclusions = ""

        for i, section in enumerate(sections):
            if "–¢–û–ü-3" in section or "TOP-3" in section:
                top_recommendations = sections[i + 1] if i + 1 < len(sections) else ""
            elif "–î–ï–¢–ê–õ–¨–ù–´–ô" in section:
                detailed_analysis = sections[i + 1] if i + 1 < len(sections) else ""
            elif "–û–ë–©–ò–ï" in section or "–í–´–í–û–î–´" in section:
                general_conclusions = sections[i + 1] if i + 1 < len(sections) else ""

        recommended_ids = self._extract_recommended_car_ids(top_recommendations, cars)

        return {
            "total_cars_analyzed": len(cars),
            "top_recommendations": top_recommendations.strip(),
            "detailed_analysis": detailed_analysis.strip(),
            "general_conclusions": general_conclusions.strip(),
            "full_analysis": analysis_text,
            "recommended_car_ids": recommended_ids,
            "model_used": "o3-mini",
            "api_version": "responses_v1",
            "cars_data": [
                {
                    "id": car.id,
                    "title": car.title,
                    "brand": car.brand,
                    "year": car.year,
                    "price": car.price,
                    "mileage": car.mileage,
                    "link": car.link,
                    "description": car.description[:200] + "..." if car.description and len(
                        car.description) > 200 else car.description
                } for car in cars
            ]
        }

    async def get_quick_recommendation(self, cars: List[Car]) -> str:
        """–ë—ã—Å—Ç—Ä–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è (legacy)"""
        if not cars:
            return "–ù–µ—Ç –º–∞—à–∏–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"

        try:
            cars_data = self._prepare_cars_data(cars[:5])
            input_text = f"""–¢—ã –∞–≤—Ç–æ—ç–∫—Å–ø–µ—Ä—Ç –Ω–∞ –ö–∏–ø—Ä–µ. –ò–∑ —ç—Ç–∏—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π –≤—ã–±–µ—Ä–∏ –û–î–ù–£ –ª—É—á—à—É—é –ø–æ–∫—É–ø–∫—É:

{cars_data}

–í–ê–ñ–ù–û: –û–±—Ä–∞—â–∞–π –æ—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –û–ü–ò–°–ê–ù–ò–Ø –º–∞—à–∏–Ω - —Ç–∞–º –º–æ–∂–µ—Ç –±—ã—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ:
- –°—Ä–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–æ–¥–∞–∂–∏
- –†–µ–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏
- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–º –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–∏
- –°–µ—Ä–≤–∏—Å–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏
- –°–∫—Ä—ã—Ç—ã—Ö –ø—Ä–æ–±–ª–µ–º–∞—Ö

–û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º: "–†–µ–∫–æ–º–µ–Ω–¥—É—é –ê–≤—Ç–æ–º–æ–±–∏–ª—å #X –ø–æ—Ç–æ–º—É —á—Ç–æ [–∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞ —Å —É—á–µ—Ç–æ–º –æ–ø–∏—Å–∞–Ω–∏—è]"
"""
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/responses",
                    headers={
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {self.api_key}"
                    },
                    json={
                        "model": "o3-mini",
                        "input": input_text
                    },
                    timeout=30.0
                )

                if response.status_code == 200:
                    result = response.json()
                    return self._extract_response_text(result)
                else:
                    return "–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"

        except Exception as e:
            logger.error(f"Quick recommendation error: {e}")
            return "–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"

    async def test_connection(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ API"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/responses",
                    headers={
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {self.api_key}"
                    },
                    json={
                        "model": "o3-mini",
                        "input": "–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –Ω–æ–≤–æ–º—É API"
                    },
                    timeout=15.0
                )

                if response.status_code == 200:
                    result = response.json()
                    return {
                        "status": "success",
                        "model": "o3-mini",
                        "api_version": "responses_v1",
                        "response": self._extract_response_text(result)
                    }
                else:
                    return {
                        "status": "error",
                        "model": "o3-mini",
                        "error": f"HTTP {response.status_code}: {response.text}"
                    }

        except Exception as e:
            return {
                "status": "error",
                "model": "o3-mini",
                "error": str(e)
            }

    async def get_available_models(self) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    f"{self.base_url}/models",
                    headers={"Authorization": f"Bearer {self.api_key}"},
                    timeout=10.0
                )
                if response.status_code == 200:
                    models_data = response.json()
                    available = [model["id"] for model in models_data.get("data", [])
                                 if any(keyword in model["id"] for keyword in ['gpt', 'o3', 'o1'])]
                    return sorted(available)
                else:
                    return ["o3-mini"]
        except Exception as e:
            logger.error(f"Failed to get models: {e}")
            return ["o3-mini"]

    async def detect_urgent_sale(self, text: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å—Ä–æ—á–Ω–æ–π –ø—Ä–æ–¥–∞–∂–∏"""
        if not text:
            return False
        try:
            prompt = f"–û—Ç–≤–µ—Ç—å 'yes' –∏–ª–∏ 'no'. –í —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å—Ä–æ—á–Ω–æ–π –ø—Ä–æ–¥–∞–∂–∏?\n\n{text}"
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/responses",
                    headers={
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {self.api_key}"
                    },
                    json={"model": "o3-mini", "input": prompt},
                    timeout=20.0,
                )
                if response.status_code == 200:
                    result = response.json()
                    answer = self._extract_response_text(result).lower()
                    return "yes" in answer or "–¥–∞" in answer
        except Exception as e:
            logger.error(f"Urgent sale detection failed: {e}")
        return False