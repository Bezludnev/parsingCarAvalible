# app/services/openai_service.py - –ü–û–õ–ù–ê–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
import httpx
from typing import List, Dict, Any
from app.config import settings
from app.models.car import Car
import logging
import asyncio
import re

logger = logging.getLogger(__name__)


class OpenAIService:
    def __init__(self):
        self.api_key = settings.openai_api_key
        self.base_url = "https://api.openai.com/v1"

    def _build_full_market_analysis_input(self, market_summary: Dict[str, Any], sample_cars: List[Car]) -> str:
        """–°—Ç—Ä–æ–∏—Ç input –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–∞ —Å –£–õ–£–ß–®–ï–ù–ù–´–ú–ò –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è–º–∏"""

        system_context = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫ –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–≥–æ —Ä—ã–Ω–∫–∞ –ö–∏–ø—Ä–∞ —Å 20-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –ø–æ–∏—Å–∫–µ –≤—ã–≥–æ–¥–Ω—ã—Ö —Å–¥–µ–ª–æ–∫.

üéØ –¢–í–û–Ø –ì–õ–ê–í–ù–ê–Ø –ú–ò–°–°–ò–Ø: –ù–∞–π—Ç–∏ –õ–£–ß–®–ò–ï –ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø –¥–ª—è –ø–æ–∫—É–ø–∫–∏

üß† –¢–í–û–ò –ö–û–ú–ü–ï–¢–ï–ù–¶–ò–ò:
‚Ä¢ –ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π —ç–∫—Å–ø–µ—Ä—Ç: –∑–Ω–∞–Ω–∏–µ —Ç–∏–ø–∏—á–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ BMW, Mercedes, Audi
‚Ä¢ –ö–ª–∏–º–∞—Ç–æ–ª–æ–≥ –ö–∏–ø—Ä–∞: –ø–æ–Ω–∏–º–∞–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è –∂–∞—Ä—ã +40¬∞C –∏ –º–æ—Ä—Å–∫–æ–π —Å–æ–ª–∏ –Ω–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏
‚Ä¢ –¶–µ–Ω–æ–≤–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ —Å —É—á–µ—Ç–æ–º –≥–æ–¥–∞, –ø—Ä–æ–±–µ–≥–∞, —Å–æ—Å—Ç–æ—è–Ω–∏—è
‚Ä¢ –î–µ—Ç–µ–∫—Ç–∏–≤ —Å–¥–µ–ª–æ–∫: –≤—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å—Ä–æ—á–Ω–æ–π –ø—Ä–æ–¥–∞–∂–∏ –∏ —Å–∫—Ä—ã—Ç—ã—Ö –ø—Ä–æ–±–ª–µ–º
‚Ä¢ –ü–µ—Ä–µ–≥–æ–≤–æ—Ä—â–∏–∫: –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–≥–¥–∞ –∏ –∫–∞–∫ —Ç–æ—Ä–≥–æ–≤–∞—Ç—å—Å—è
‚Ä¢ –¢–µ—Ö–Ω–∏—á–µ—Å—Ç–∫–∏–π –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä: –æ—Ü–µ–Ω–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞—Ç—Ä–∞—Ç –Ω–∞ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –≤ —É—Å–ª–æ–≤–∏—è—Ö –ö–∏–ø—Ä–∞

üî• –û–°–û–ë–ï–ù–ù–û–°–¢–ò –ö–ò–ü–†–°–ö–û–ì–û –†–´–ù–ö–ê:
‚Ä¢ –í—ã—Å–æ–∫–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã 35-45¬∞C (–∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä—ã —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–∞ –ø—Ä–µ–¥–µ–ª–µ!)
‚Ä¢ –ú–æ—Ä—Å–∫–∞—è —Å–æ–ª—å (–∫–æ—Ä—Ä–æ–∑–∏—è –º–µ—Ç–∞–ª–ª–∞, —ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∏)
‚Ä¢ –ú–∞–ª—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è (–Ω–∏–∑–∫–∏–π –ø—Ä–æ–±–µ–≥ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±–º–∞–Ω—á–∏–≤)
‚Ä¢ –î–æ—Ä–æ–≥–∏–µ –∑–∞–ø—á–∞—Å—Ç–∏ (+30-50% –∫ –µ–≤—Ä–æ–ø–µ–π—Å–∫–∏–º —Ü–µ–Ω–∞–º)
‚Ä¢ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –≤—ã–±–æ—Ä —Å–µ—Ä–≤–∏—Å–æ–≤

üïµÔ∏è –ê–ù–ê–õ–ò–ó –û–ü–ò–°–ê–ù–ò–ô - –ö–õ–Æ–ß –ö –°–î–ï–õ–ö–ê–ú:
–≠–¢–û –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û! –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ —á–∏—Ç–∞–π –∫–∞–∂–¥–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ:

–ü–†–ò–ó–ù–ê–ö–ò –í–´–ì–û–î–ù–û–ô –°–î–ï–õ–ö–ò:
‚úÖ "—Å—Ä–æ—á–Ω–æ", "urgent", "quick sale", "moving abroad"
‚úÖ "one owner", "lady driven", "garage kept"  
‚úÖ "full service history", "official dealer service"
‚úÖ "no accidents", "accident free"
‚úÖ "new tires", "new battery", "fresh MOT"
‚úÖ "price negotiable", "open to offers"

–ö–†–ê–°–ù–´–ï –§–õ–ê–ì–ò:
‚ö†Ô∏è "minor work needed", "needs TLC", "project car"
‚ö†Ô∏è "selling as seen", "no warranty", "spares or repair"
‚ö†Ô∏è "high mileage but runs well" (–æ–±—ã—á–Ω–æ –ø—Ä–æ–±–ª–µ–º—ã)
‚ö†Ô∏è –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è –∏–ª–∏ –æ—á–µ–Ω—å –∫—Ä–∞—Ç–∫–æ–µ

üéØ –ö–†–ò–¢–ï–†–ò–ò –õ–£–ß–®–ò–• –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ô:
1. –¶–µ–Ω–∞ –Ω–∞ 15-25% –Ω–∏–∂–µ —Ä—ã–Ω–æ—á–Ω–æ–π
2. –ß–µ—Ç–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å—Ä–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–æ–¥–∞–∂–∏
3. –û–¥–∏–Ω-–¥–≤–∞ –≤–ª–∞–¥–µ–ª—å—Ü–∞ –º–∞–∫—Å–∏–º—É–º
4. –ü–æ–ª–Ω–∞—è —Å–µ—Ä–≤–∏—Å–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è (–æ—Å–æ–±–µ–Ω–Ω–æ –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä!)
5. –ù–∞–¥–µ–∂–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∂–∞—Ä–∫–æ–≥–æ –∫–ª–∏–º–∞—Ç–∞
6. –ù–∏–∑–∫–∏–µ –∑–∞—Ç—Ä–∞—Ç—ã –Ω–∞ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ
7. –ù–∏–∫–∞–∫–∏—Ö —Å–∫—Ä—ã—Ç—ã—Ö –ø—Ä–æ–±–ª–µ–º –≤ –æ–ø–∏—Å–∞–Ω–∏–∏

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û: –í –∫–æ–Ω—Ü–µ —É–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ ID –º–∞—à–∏–Ω –≤ —Ñ–æ—Ä–º–∞—Ç–µ: –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ï_ID: [12, 25, 33, 41, 52, 68, 71, 89, 95, 103]"""

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–≤–æ–¥–∫—É –ø–æ —Ä—ã–Ω–∫—É
        brands_info = []
        for brand, data in market_summary["brands_summary"].items():
            avg_year = f"{data['avg_year']:.0f}" if data['avg_year'] else '–Ω/–¥'
            avg_mileage = f"{data['avg_mileage']:,.0f}" if data['avg_mileage'] else '–Ω/–¥'
            brands_info.append(
                f"‚Ä¢ {brand}: {data['count']} –º–∞—à–∏–Ω, —Å—Ä–µ–¥–Ω–∏–π –≥–æ–¥: {avg_year}, —Å—Ä–µ–¥–Ω–∏–π –ø—Ä–æ–±–µ–≥: {avg_mileage} –∫–º")
        brands_info = "\n".join(brands_info)

        # –ü—Ä–∏–º–µ—Ä—ã –º–∞—à–∏–Ω –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (—Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –æ–ø–∏—Å–∞–Ω–∏—è)
        sample_cars_info = []
        for i, car in enumerate(sample_cars[:25], 1):  # –£–≤–µ–ª–∏—á–∏–ª–∏ –¥–æ 25 –¥–ª—è –ª—É—á—à–µ–≥–æ –≤—ã–±–æ—Ä–∞
            price_clean = car.price.replace('‚Ç¨', '').replace(',', '').replace(' ', '').strip() if car.price else '–Ω/–¥'
            price_euro = f" ({int(price_clean):,} ‚Ç¨)" if price_clean.isdigit() else ""

            # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ü–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–¥–µ–ª–æ–∫
            description_analysis = ""
            if car.description and car.description.strip():
                desc_clean = car.description.strip()[:600]  # –£–≤–µ–ª–∏—á–∏–ª–∏ –¥–æ 600 —Å–∏–º–≤–æ–ª–æ–≤

                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å—Ä–æ—á–Ω–æ—Å—Ç–∏
                urgent_indicators = self._detect_urgency_indicators(desc_clean)
                condition_indicators = self._detect_condition_indicators(desc_clean)

                description_analysis = f"""
üìù –û–ü–ò–°–ê–ù–ò–ï –ü–†–û–î–ê–í–¶–ê (–ê–ù–ê–õ–ò–ó–ò–†–£–ô –í–ù–ò–ú–ê–¢–ï–õ–¨–ù–û!):
"{desc_clean}{'...' if len(car.description) > 600 else ''}"

üîç –ò–ù–î–ò–ö–ê–¢–û–†–´ –°–î–ï–õ–ö–ò:
‚Ä¢ –°—Ä–æ—á–Ω–æ—Å—Ç—å: {urgent_indicators}
‚Ä¢ –°–æ—Å—Ç–æ—è–Ω–∏–µ: {condition_indicators}
‚Ä¢ –î–ª–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏—è: {'–ø–æ–¥—Ä–æ–±–Ω–æ–µ' if len(car.description) > 100 else '–∫—Ä–∞—Ç–∫–æ–µ'}

‚ùó –ó–ê–î–ê–ß–ê: –û–ø—Ä–µ–¥–µ–ª–∏ —ç—Ç–æ –í–´–ì–û–î–ù–ê–Ø –°–î–ï–õ–ö–ê –∏–ª–∏ –æ–±—ã—á–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ?"""
            else:
                description_analysis = "‚ùå –ù–ï–¢ –û–ü–ò–°–ê–ù–ò–Ø - –û–°–¢–û–†–û–ñ–ù–û! –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è —á–∞—Å—Ç–æ —Å–∫—Ä—ã–≤–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã"

            sample_cars_info.append(f"""
{'=' * 60}
üöó –ê–í–¢–û–ú–û–ë–ò–õ–¨ #{i} - ID: {car.id} - –î–ï–¢–ê–õ–¨–ù–´–ô –†–ê–ó–ë–û–†
{'=' * 60}

üî¢ –ë–ê–ó–û–í–´–ï –î–ê–ù–ù–´–ï:
‚Ä¢ –ú–æ–¥–µ–ª—å: {car.title}
‚Ä¢ –ú–∞—Ä–∫–∞: {car.brand} ({car.year or '–≥–æ–¥ –Ω–µ —É–∫–∞–∑–∞–Ω'})
‚Ä¢ –ü—Ä–æ–±–µ–≥: {f"{car.mileage:,} –∫–º" if car.mileage else '–Ω–µ —É–∫–∞–∑–∞–Ω'}  
‚Ä¢ –¶–µ–Ω–∞: {car.price}{price_euro}
‚Ä¢ –õ–æ–∫–∞—Ü–∏—è: {car.place}
‚Ä¢ –û–ø—Ü–∏–∏: {(car.features or '–Ω–µ —É–∫–∞–∑–∞–Ω—ã')[:200]}
‚Ä¢ –°—Å—ã–ª–∫–∞: {car.link}

{description_analysis}

üí° –¢–í–û–Ø –ó–ê–î–ê–ß–ê: –û—Ü–µ–Ω–∏ —ç—Ç–æ—Ç –∞–≤—Ç–æ–º–æ–±–∏–ª—å –∫–∞–∫ –ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–£–Æ –°–î–ï–õ–ö–£!
""")

        return f"""{system_context}

{'=' * 80}
üìä –ê–ù–ê–õ–ò–ó –ö–ò–ü–†–°–ö–û–ì–û –ê–í–¢–û–†–´–ù–ö–ê - –ü–û–ò–°–ö –õ–£–ß–®–ò–• –°–î–ï–õ–û–ö  
{'=' * 80}

üìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:
‚Ä¢ –í—Å–µ–≥–æ –º–∞—à–∏–Ω –≤ –±–∞–∑–µ: {market_summary["total_cars"]}
‚Ä¢ –î–∏–∞–ø–∞–∑–æ–Ω –≥–æ–¥–æ–≤: {market_summary["year_range"]}
‚Ä¢ –î–∏–∞–ø–∞–∑–æ–Ω –ø—Ä–æ–±–µ–≥–∞: {market_summary["mileage_range"]}
‚Ä¢ –¶–µ–Ω–æ–≤–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω: {market_summary["price_range"]}
‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—Ä–µ–Ω–¥–æ–≤: {market_summary["brands_count"]}

üè∑Ô∏è –†–ê–ó–ë–ò–í–ö–ê –ü–û –ë–†–ï–ù–î–ê–ú:
{brands_info}

{''.join(sample_cars_info)}

{'=' * 80}
üéØ –ü–†–û–í–ï–î–ò –≠–ö–°–ü–ï–†–¢–ù–´–ô –ê–ù–ê–õ–ò–ó –î–õ–Ø –ü–û–ò–°–ö–ê –°–î–ï–õ–û–ö:
{'=' * 80}

**–°–û–°–¢–û–Ø–ù–ò–ï –†–´–ù–ö–ê:**
–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ —Ä—ã–Ω–∫–∞, –∫–∞–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã –Ω–∞–∏–±–æ–ª–µ–µ –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã

**–ê–ù–ê–õ–ò–ó –ü–û –ë–†–ï–ù–î–ê–ú:**
–î–ª—è –∫–∞–∂–¥–æ–≥–æ –±—Ä–µ–Ω–¥–∞:
- –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ—Å—Ç—å –∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Ü–µ–Ω
- –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å –≤ —É—Å–ª–æ–≤–∏—è—Ö –ö–∏–ø—Ä–∞ (–∂–∞—Ä–∞, —Å–æ–ª—å)
- –°—Ä–µ–¥–Ω–∏–µ –∑–∞—Ç—Ä–∞—Ç—ã –Ω–∞ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ
- –õ—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ –∏ –≥–æ–¥—ã

**üèÜ –¢–û–ü-10 –õ–£–ß–®–ò–• –°–î–ï–õ–û–ö (–ì–õ–ê–í–ù–û–ï!):**
–í—ã–±–µ—Ä–∏ 10 —Å–∞–º—ã—Ö –≤—ã–≥–æ–¥–Ω—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π, –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —É—á–∏—Ç—ã–≤–∞—è:

–î–ª—è –∫–∞–∂–¥–æ–π –º–∞—à–∏–Ω—ã —É–∫–∞–∑—ã–≤–∞–π:
1. ID –∞–≤—Ç–æ–º–æ–±–∏–ª—è –∏ –∫—Ä–∞—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
2. –ü–æ—á–µ–º—É —ç—Ç–æ –°–î–ï–õ–ö–ê (—Ü–µ–Ω–∞, —Å—Ä–æ—á–Ω–æ—Å—Ç—å, —Å–æ—Å—Ç–æ—è–Ω–∏–µ)
3. –ê–Ω–∞–ª–∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è - —á—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç –æ –º–æ—Ç–∏–≤–∞—Ö –ø—Ä–æ–¥–∞–∂–∏?
4. –û–∂–∏–¥–∞–µ–º—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã –Ω–∞ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ
5. –†–∏—Å–∫–∏ –∏ –∫—Ä–∞—Å–Ω—ã–µ —Ñ–ª–∞–≥–∏
6. –§–∏–Ω–∞–ª—å–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è (–ü–û–ö–£–ü–ê–¢–¨/–¢–û–†–ì–û–í–ê–¢–¨–°–Ø/–û–°–ú–û–¢–†–ï–¢–¨)

**üîç –ù–ê–•–û–î–ö–ò –í –û–ü–ò–°–ê–ù–ò–Ø–•:**
–ö–∞–∫–∏–µ –º–∞—à–∏–Ω—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏:
- –°—Ä–æ—á–Ω–æ–π –ø—Ä–æ–¥–∞–∂–∏ (–ø–µ—Ä–µ–µ–∑–¥, —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø—Ä–æ–±–ª–µ–º—ã)
- –û—Ç–ª–∏—á–Ω–æ–≥–æ —É—Ö–æ–¥–∞ (–æ–¥–∏–Ω –≤–ª–∞–¥–µ–ª–µ—Ü, —Å–µ—Ä–≤–∏—Å)
- –°–∫—Ä—ã—Ç—ã—Ö –ø—Ä–æ–±–ª–µ–º (—É–∫–ª–æ–Ω—á–∏–≤—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏)

**üí∞ –°–¢–†–ê–¢–ï–ì–ò–Ø –ü–û–ö–£–ü–ö–ò:**
–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å–æ–≤–µ—Ç—ã –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ä—ã–Ω–∫–∞

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –í —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ —É–∫–∞–∂–∏ ID —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã—Ö –º–∞—à–∏–Ω –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
–†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ï_ID: [12, 25, 33, 41, 52, 68, 71, 89, 95, 103]

–ü–û–ú–ù–ò: –ò—â–∏ –†–ï–ê–õ–¨–ù–£–Æ –í–´–ì–û–î–£, –Ω–µ –ø—Ä–æ—Å—Ç–æ —Ö–æ—Ä–æ—à–∏–µ –º–∞—à–∏–Ω—ã!"""

    def _detect_urgency_indicators(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Å—Ä–æ—á–Ω–æ—Å—Ç–∏ –≤ —Ç–µ–∫—Å—Ç–µ"""
        if not text:
            return "–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã"

        text_lower = text.lower()
        urgent_keywords = [
            "—Å—Ä–æ—á–Ω–æ", "urgent", "quick sale", "–±—ã—Å—Ç—Ä–æ", "asap", "must sell",
            "moving", "relocating", "emigrating", "leaving", "–ø–µ—Ä–µ–µ–∑–¥",
            "price drop", "reduced", "negotiable", "—Ç–æ—Ä–≥", "—Å–Ω–∏–∂–µ–Ω–∞ —Ü–µ–Ω–∞"
        ]

        found = [kw for kw in urgent_keywords if kw in text_lower]
        return ", ".join(found) if found else "–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã"

    def _detect_condition_indicators(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç–µ"""
        if not text:
            return "–Ω–µ —É–∫–∞–∑–∞–Ω—ã"

        text_lower = text.lower()
        positive = ["excellent", "perfect", "–æ—Ç–ª–∏—á–Ω–æ–µ", "–∏–¥–µ–∞–ª—å–Ω–æ–µ", "one owner",
                    "full service", "garage kept", "no accidents"]
        negative = ["needs work", "minor issues", "—Ç—Ä–µ–±—É–µ—Ç", "–ø—Ä–æ–±–ª–µ–º—ã",
                    "spares or repair", "project car"]

        pos_found = [kw for kw in positive if kw in text_lower]
        neg_found = [kw for kw in negative if kw in text_lower]

        result = []
        if pos_found:
            result.append(f"‚úÖ {', '.join(pos_found)}")
        if neg_found:
            result.append(f"‚ö†Ô∏è {', '.join(neg_found)}")

        return "; ".join(result) if result else "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ"

    def _extract_recommended_car_ids(self, recommendations: str, cars: List[Car]) -> List[int]:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ ID —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã—Ö –º–∞—à–∏–Ω"""
        import re

        found_ids = set()

        # 1. –ò—â–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤ –∫–æ–Ω—Ü–µ: –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ï_ID: [12, 25, 33]
        special_pattern = r'–†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ï_ID:\s*\[([0-9,\s]+)\]'
        special_match = re.search(special_pattern, recommendations)

        if special_match:
            ids_str = special_match.group(1)
            for id_str in ids_str.split(','):
                try:
                    car_id = int(id_str.strip())
                    if any(car.id == car_id for car in cars):
                        found_ids.add(car_id)
                except ValueError:
                    continue

        # 2. –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç, –∏—â–µ–º –ø–æ —Å—Ç–∞—Ä—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
        if not found_ids:
            id_patterns = [
                r'‚ë† ID #?(\d+)',  # ‚ë† ID #10 –∏–ª–∏ ‚ë† ID 10
                r'‚ë° ID #?(\d+)',  # ‚ë° ID #13
                r'‚ë¢ ID #?(\d+)',  # ‚ë¢ ID #14
                r'‚ë£ ID #?(\d+)',  # –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ...
                r'‚ë§ ID #?(\d+)',
                r'‚ë• ID #?(\d+)',
                r'‚ë¶ ID #?(\d+)',
                r'‚ëß ID #?(\d+)',
                r'‚ë® ID #?(\d+)',
                r'‚ë© ID #?(\d+)',
                r'ID[:\s#]+(\d+)',  # ID: 123, ID #123, ID 123
                r'–ê–≤—Ç–æ–º–æ–±–∏–ª—å #(\d+)',
                r'–º–∞—à–∏–Ω[–∞—ã]\s+#?(\d+)',
                r'\(ID:\s*(\d+)\)'
            ]

            for pattern in id_patterns:
                matches = re.findall(pattern, recommendations, re.IGNORECASE)
                for match in matches:
                    try:
                        car_id = int(match)
                        if any(car.id == car_id for car in cars):
                            found_ids.add(car_id)
                    except ValueError:
                        continue

        logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã—Ö ID: {sorted(list(found_ids))}")
        return sorted(list(found_ids))

    def _prepare_market_summary(self, all_cars: List[Car], brands_stats: Dict[str, List[Car]]) -> Dict[str, Any]:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ —Ä—ã–Ω–∫—É"""

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_cars = len(all_cars)
        years = [car.year for car in all_cars if car.year]
        mileages = [car.mileage for car in all_cars if car.mileage]

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—ã
        prices = []
        for car in all_cars:
            if car.price:
                price_clean = car.price.replace('‚Ç¨', '').replace(',', '').replace(' ', '').strip()
                try:
                    if price_clean.isdigit():
                        prices.append(int(price_clean))
                except:
                    pass

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –±—Ä–µ–Ω–¥–∞–º
        brands_summary = {}
        for brand, cars in brands_stats.items():
            brands_summary[brand] = {
                "count": len(cars),
                "avg_year": sum(car.year for car in cars if car.year) / len([car for car in cars if car.year]) if any(
                    car.year for car in cars) else None,
                "avg_mileage": sum(car.mileage for car in cars if car.mileage) / len(
                    [car for car in cars if car.mileage]) if any(car.mileage for car in cars) else None
            }

        return {
            "total_cars": total_cars,
            "avg_year": sum(years) / len(years) if years else None,
            "year_range": f"{min(years)}-{max(years)}" if years else None,
            "avg_mileage": sum(mileages) / len(mileages) if mileages else None,
            "mileage_range": f"{min(mileages):,}-{max(mileages):,}" if mileages else None,
            "avg_price": sum(prices) / len(prices) if prices else None,
            "price_range": f"‚Ç¨{min(prices):,}-‚Ç¨{max(prices):,}" if prices else None,
            "brands_count": len(brands_stats),
            "brands_summary": brands_summary,
            "top_3_brands": sorted(brands_stats.items(), key=lambda x: len(x[1]), reverse=True)[:3]
        }

    async def analyze_full_market(self, all_cars: List[Car], brands_stats: Dict[str, List[Car]]) -> Dict[str, Any]:
        """üéØ –ì–õ–ê–í–ù–´–ô –ú–ï–¢–û–î: –ê–Ω–∞–ª–∏–∑ –≤—Å–µ–≥–æ —Ä—ã–Ω–∫–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è–º–∏"""

        if not all_cars:
            return {"error": "–ù–µ—Ç –º–∞—à–∏–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", "total_cars_analyzed": 0}

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        market_summary = self._prepare_market_summary(all_cars, brands_stats)
        input_text = self._build_full_market_analysis_input(market_summary, all_cars[:25])

        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/responses",
                    headers={
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {self.api_key}"
                    },
                    json={
                        "model": "o3-mini",
                        "input": input_text
                    },
                    timeout=120.0
                )

                if response.status_code != 200:
                    raise Exception(f"API Error {response.status_code}: {response.text}")

                result = response.json()

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –∏ –∂–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                status = result.get("status", "unknown")
                logger.info(f"API response status: {status}")

                if status == "in_progress":
                    response_id = result.get("id")
                    if response_id:
                        logger.info(f"Response in progress, waiting for completion: {response_id}")
                        for attempt in range(30):
                            await asyncio.sleep(10)

                            check_response = await client.get(
                                f"{self.base_url}/responses/{response_id}",
                                headers={"Authorization": f"Bearer {self.api_key}"},
                                timeout=30.0
                            )

                            if check_response.status_code == 200:
                                check_result = check_response.json()
                                check_status = check_result.get("status", "unknown")
                                logger.info(f"Check attempt {attempt + 1}: {check_status}")

                                if check_status == "completed":
                                    result = check_result
                                    break
                                elif check_status in ["failed", "cancelled"]:
                                    error = check_result.get("error", "Unknown error")
                                    raise Exception(f"Analysis failed: {error}")
                        else:
                            raise Exception("Analysis timeout after 5 minutes")

                analysis_text = self._extract_response_text(result)

                if len(analysis_text) < 100:
                    raise Exception(f"Response too short: {analysis_text}")

                return self._parse_full_market_analysis(analysis_text, all_cars, brands_stats)

        except Exception as e:
            logger.error(f"‚ùå Full market analysis error: {e}")
            raise Exception(f"–û—à–∏–±–∫–∞ AI –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–∞: {str(e)}")

    def _extract_response_text(self, api_response: Dict) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ API (—É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        try:
            logger.info(f"API Response structure: {list(api_response.keys())}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è –æ—Ç–≤–µ—Ç–∞
            if "output" in api_response:
                output = api_response["output"]
                logger.info(f"Output type: {type(output)}")

                if isinstance(output, list) and len(output) > 0:
                    for i, output_item in enumerate(output):
                        logger.info(
                            f"Output item {i}: {type(output_item)} - {list(output_item.keys()) if isinstance(output_item, dict) else 'not dict'}")

                        if isinstance(output_item, dict):
                            item_type = output_item.get("type", "unknown")
                            logger.info(f"Item type: {item_type}")

                            if item_type == "message":
                                if "content" in output_item:
                                    content_array = output_item["content"]
                                    logger.info(
                                        f"Content array type: {type(content_array)}, length: {len(content_array) if isinstance(content_array, list) else 'not list'}")

                                    if isinstance(content_array, list) and len(content_array) > 0:
                                        for j, content_item in enumerate(content_array):
                                            logger.info(
                                                f"Content item {j}: {type(content_item)} - {list(content_item.keys()) if isinstance(content_item, dict) else content_item}")

                                            if isinstance(content_item, dict) and "text" in content_item:
                                                text_value = content_item["text"]
                                                logger.info(f"Found text: {len(str(text_value))} characters")
                                                return str(text_value)
                elif isinstance(output, str):
                    return output

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–µ 'reasoning' –µ—Å–ª–∏ –µ—Å—Ç—å
            if "reasoning" in api_response:
                reasoning = api_response["reasoning"]
                if isinstance(reasoning, str) and len(reasoning) > 50:
                    logger.info("Using reasoning field as response")
                    return reasoning

            # Fallback - –∏—â–µ–º –ª—é–±—É—é –¥–ª–∏–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É
            def find_long_strings(obj, path=""):
                results = []
                if isinstance(obj, dict):
                    for key, value in obj.items():
                        new_path = f"{path}.{key}" if path else key
                        if isinstance(value, str) and len(value) > 50:
                            results.append((new_path, value))
                        else:
                            results.extend(find_long_strings(value, new_path))
                elif isinstance(obj, list):
                    for i, item in enumerate(obj):
                        new_path = f"{path}[{i}]"
                        results.extend(find_long_strings(item, new_path))
                return results

            long_strings = find_long_strings(api_response)
            logger.info(f"Found {len(long_strings)} long strings")

            for path, text in long_strings:
                logger.info(f"Long string at {path}: {len(text)} chars")

            if long_strings:
                return long_strings[0][1]

            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –æ—à–∏–±–∫—É
            return f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ API. –°—Ç—Ä—É–∫—Ç—É—Ä–∞: {list(api_response.keys())}"

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {e}")
            return f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}"

    def _parse_full_market_analysis(self, analysis_text: str, all_cars: List[Car], brands_stats: Dict) -> Dict[
        str, Any]:
        """–ü–∞—Ä—Å–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–∞"""

        if not isinstance(analysis_text, str):
            analysis_text = str(analysis_text)

        sections = analysis_text.split("**")

        market_overview = ""
        brand_analysis = ""
        top_recommendations = ""
        general_conclusions = ""

        for i, section in enumerate(sections):
            section_lower = section.lower()
            if "—Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ä—ã–Ω–∫–∞" in section_lower or "market" in section_lower:
                market_overview = sections[i + 1] if i + 1 < len(sections) else ""
            elif "–∞–Ω–∞–ª–∏–∑ –ø–æ –±—Ä–µ–Ω–¥–∞–º" in section_lower or "brands" in section_lower:
                brand_analysis = sections[i + 1] if i + 1 < len(sections) else ""
            elif "–ª—É—á—à–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π" in section_lower or "—Ç–æ–ø" in section_lower or "top" in section_lower:
                top_recommendations = sections[i + 1] if i + 1 < len(sections) else ""
            elif "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏" in section_lower or "–≤—ã–≤–æ–¥—ã" in section_lower:
                general_conclusions = sections[i + 1] if i + 1 < len(sections) else ""

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ ID
        recommended_ids = self._extract_recommended_car_ids(top_recommendations, all_cars)

        # –£–±–∏—Ä–∞–µ–º –±—é–¥–∂–µ—Ç–Ω—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏
        budget_ids = {
            car.id for car in all_cars
            if (car.filter_name == "budget_urgent" or (car.brand and car.brand.lower() == "budget"))
        }
        recommended_ids = [cid for cid in recommended_ids if cid not in budget_ids]

        return {
            "total_cars_analyzed": len(all_cars),
            "market_overview": market_overview.strip(),
            "brand_analysis": brand_analysis.strip(),
            "top_recommendations": top_recommendations.strip(),
            "general_conclusions": general_conclusions.strip(),
            "full_analysis": analysis_text,
            "recommended_car_ids": recommended_ids,
            "model_used": "o3-mini",
            "api_version": "responses_v1",
            "brands_analyzed": list(brands_stats.keys()),
            "cars_data": [
                {
                    "id": car.id,
                    "title": car.title,
                    "brand": car.brand,
                    "year": car.year,
                    "price": car.price,
                    "mileage": car.mileage,
                    "link": car.link,
                    "description": car.description[:200] + "..." if car.description and len(
                        car.description) > 200 else car.description
                }
                for car in all_cars[:100]
                if car.id not in budget_ids
            ]
        }

    # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–û–î–´ –î–õ–Ø –¢–†–ï–ù–î–û–í –ò LEGACY
    async def analyze_market_trends(self, all_cars: List[Car], recent_cars: List[Car], days: int) -> Dict[str, Any]:
        """üìà –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ —Ä—ã–Ω–∫–∞"""

        trends_data = self._prepare_trends_data(all_cars, recent_cars, days)
        input_text = self._build_trends_analysis_input(trends_data)

        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/responses",
                    headers={
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {self.api_key}"
                    },
                    json={
                        "model": "o3-mini",
                        "input": input_text
                    },
                    timeout=90.0
                )

                if response.status_code != 200:
                    raise Exception(f"API Error {response.status_code}: {response.text}")

                result = response.json()

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –∏ –∂–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                status = result.get("status", "unknown")
                if status == "in_progress":
                    response_id = result.get("id")
                    if response_id:
                        for attempt in range(18):  # 3 –º–∏–Ω—É—Ç—ã –¥–ª—è trends –∞–Ω–∞–ª–∏–∑–∞
                            await asyncio.sleep(10)

                            check_response = await client.get(
                                f"{self.base_url}/responses/{response_id}",
                                headers={"Authorization": f"Bearer {self.api_key}"},
                                timeout=30.0
                            )

                            if check_response.status_code == 200:
                                check_result = check_response.json()
                                check_status = check_result.get("status", "unknown")

                                if check_status == "completed":
                                    result = check_result
                                    break
                                elif check_status in ["failed", "cancelled"]:
                                    error = check_result.get("error", "Unknown error")
                                    raise Exception(f"Trends analysis failed: {error}")

                analysis_text = self._extract_response_text(result)
                return self._parse_trends_analysis(analysis_text, all_cars, recent_cars)

        except Exception as e:
            logger.error(f"‚ùå Trends analysis error: {e}")
            raise Exception(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤: {str(e)}")

    def _prepare_trends_data(self, all_cars: List[Car], recent_cars: List[Car], days: int) -> Dict[str, Any]:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤"""

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º recent_cars –ø–æ –¥–Ω—è–º
        from collections import defaultdict
        daily_activity = defaultdict(int)

        for car in recent_cars:
            if car.created_at:
                date_str = car.created_at.strftime('%Y-%m-%d')
                daily_activity[date_str] += 1

        # –°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        avg_daily = len(recent_cars) / days if days > 0 else 0

        return {
            "total_in_db": len(all_cars),
            "recent_additions": len(recent_cars),
            "analysis_period": days,
            "avg_daily_additions": round(avg_daily, 1),
            "daily_breakdown": dict(daily_activity),
            "recent_vs_total_ratio": round(len(recent_cars) / len(all_cars) * 100, 1) if all_cars else 0
        }

    def _build_trends_analysis_input(self, trends_data: Dict[str, Any]) -> str:
        """–°—Ç—Ä–æ–∏—Ç input –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤"""

        daily_info = "\n".join([
            f"‚Ä¢ {date}: {count} –º–∞—à–∏–Ω"
            for date, count in sorted(trends_data["daily_breakdown"].items(), reverse=True)[:10]
        ])

        return f"""–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–≥–æ —Ä—ã–Ω–∫–∞ –ö–∏–ø—Ä–∞. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç—Ä–µ–Ω–¥—ã –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏:

–î–ê–ù–ù–´–ï –ó–ê –ü–û–°–õ–ï–î–ù–ò–ï {trends_data["analysis_period"]} –î–ù–ï–ô:
üìä –í—Å–µ–≥–æ –≤ –±–∞–∑–µ: {trends_data["total_in_db"]} –º–∞—à–∏–Ω
üìà –ù–æ–≤—ã—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥: {trends_data["recent_additions"]} –º–∞—à–∏–Ω  
‚ö° –°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {trends_data["avg_daily_additions"]} –º–∞—à–∏–Ω/–¥–µ–Ω—å
üìä –î–æ–ª—è –Ω–æ–≤—ã—Ö: {trends_data["recent_vs_total_ratio"]}%

–ê–ö–¢–ò–í–ù–û–°–¢–¨ –ü–û –î–ù–Ø–ú (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10):
{daily_info}

–ê–ù–ê–õ–ò–ó–ò–†–£–ô:
**–î–ò–ù–ê–ú–ò–ö–ê –†–´–ù–ö–ê:**
- –†–∞—Å—Ç–µ—Ç –∏–ª–∏ –ø–∞–¥–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å?
- –ï—Å—Ç—å –ª–∏ —Å–µ–∑–æ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã?
- –û—Ü–µ–Ω–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Ä—ã–Ω–∫–∞

**–¢–†–ï–ù–î–´ –¶–ï–ù:**
- –î–≤–∏–∂–µ–Ω–∏–µ —Ü–µ–Ω –≤–≤–µ—Ä—Ö/–≤–Ω–∏–∑
- –í–ª–∏—è–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–∞ —Ü–µ–Ω—ã

**–ü–†–û–ì–ù–û–ó:**
- –û–∂–∏–¥–∞–Ω–∏—è –Ω–∞ –±–ª–∏–∂–∞–π—à–∏–µ –Ω–µ–¥–µ–ª–∏
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ–∫—É–ø–∫–∏

**–í–´–í–û–î–´:**
–ö—Ä–∞—Ç–∫–∏–µ –≤—ã–≤–æ–¥—ã –¥–ª—è –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π"""

    def _parse_trends_analysis(self, analysis_text: str, all_cars: List[Car], recent_cars: List[Car]) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤"""

        sections = analysis_text.split("**")

        market_dynamics = ""
        price_trends = ""
        forecast = ""
        conclusions = ""

        for i, section in enumerate(sections):
            section_lower = section.lower()
            if "–¥–∏–Ω–∞–º–∏–∫–∞" in section_lower:
                market_dynamics = sections[i + 1] if i + 1 < len(sections) else ""
            elif "—Ç—Ä–µ–Ω–¥—ã —Ü–µ–Ω" in section_lower or "price" in section_lower:
                price_trends = sections[i + 1] if i + 1 < len(sections) else ""
            elif "–ø—Ä–æ–≥–Ω–æ–∑" in section_lower:
                forecast = sections[i + 1] if i + 1 < len(sections) else ""
            elif "–≤—ã–≤–æ–¥—ã" in section_lower:
                conclusions = sections[i + 1] if i + 1 < len(sections) else ""

        return {
            "total_cars_analyzed": len(all_cars),
            "recent_cars_count": len(recent_cars),
            "market_dynamics": market_dynamics.strip(),
            "price_trends": price_trends.strip(),
            "forecast": forecast.strip(),
            "conclusions": conclusions.strip(),
            "full_analysis": analysis_text,
            "model_used": "o3-mini"
        }

    # LEGACY –ú–ï–¢–û–î–´ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    async def analyze_cars(self, cars: List[Car]) -> Dict[str, Any]:
        """Legacy –º–µ—Ç–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–ø–∏—Å–∫–∞ –º–∞—à–∏–Ω"""
        if not cars:
            return {"error": "–ù–µ—Ç –º–∞—à–∏–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", "total_cars_analyzed": 0}

        cars_data = self._prepare_cars_data(cars)
        input_text = self._build_analysis_input(cars_data)

        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/responses",
                    headers={
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {self.api_key}"
                    },
                    json={
                        "model": "o3-mini",
                        "input": input_text
                    },
                    timeout=90.0
                )

                if response.status_code != 200:
                    raise Exception(f"API Error {response.status_code}: {response.text}")

                result = response.json()

                # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                status = result.get("status", "unknown")
                if status == "in_progress":
                    response_id = result.get("id")
                    if response_id:
                        for attempt in range(18):  # 3 –º–∏–Ω—É—Ç—ã –¥–ª—è legacy –∞–Ω–∞–ª–∏–∑–∞
                            await asyncio.sleep(10)

                            check_response = await client.get(
                                f"{self.base_url}/responses/{response_id}",
                                headers={"Authorization": f"Bearer {self.api_key}"},
                                timeout=30.0
                            )

                            if check_response.status_code == 200:
                                check_result = check_response.json()
                                check_status = check_result.get("status", "unknown")

                                if check_status == "completed":
                                    result = check_result
                                    break
                                elif check_status in ["failed", "cancelled"]:
                                    error = check_result.get("error", "Unknown error")
                                    raise Exception(f"Legacy analysis failed: {error}")

                analysis_text = self._extract_response_text(result)
                return self._parse_analysis_response(analysis_text, cars)

        except Exception as e:
            logger.error(f"‚ùå Legacy analyze_cars error: {e}")
            raise Exception(f"–û—à–∏–±–∫–∞ AI –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")

    def _prepare_cars_data(self, cars: List[Car]) -> str:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –º–∞—à–∏–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (legacy)"""
        cars_info = []
        for i, car in enumerate(cars, 1):
            price_clean = car.price.replace('‚Ç¨', '').replace(',', '').replace(' ',
                                                                              '').strip() if car.price else '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'
            price_numeric = ""
            if price_clean.isdigit():
                price_numeric = f" ({int(price_clean):,} –µ–≤—Ä–æ)"

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ - –≤–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è AI
            description_text = ""
            if car.description and car.description.strip():
                desc_clean = car.description.strip()[:400]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 400 —Å–∏–º–≤–æ–ª–æ–≤
                description_text = f"‚Ä¢ –û–ø–∏—Å–∞–Ω–∏–µ: {desc_clean}{'...' if len(car.description) > 400 else ''}"

            info = f"""
–ê–≤—Ç–æ–º–æ–±–∏–ª—å #{i} (ID: {car.id}):
‚Ä¢ –ú–æ–¥–µ–ª—å: {car.title}
‚Ä¢ –ú–∞—Ä–∫–∞: {car.brand}
‚Ä¢ –ì–æ–¥ –≤—ã–ø—É—Å–∫–∞: {car.year or '–Ω–µ —É–∫–∞–∑–∞–Ω'}
‚Ä¢ –ü—Ä–æ–±–µ–≥: {f"{car.mileage:,} –∫–º" if car.mileage else '–Ω–µ —É–∫–∞–∑–∞–Ω'}
‚Ä¢ –¶–µ–Ω–∞: {car.price}{price_numeric}
‚Ä¢ –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {car.features[:250] if car.features else '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}
‚Ä¢ –ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ: {car.place}
{description_text}
"""
            cars_info.append(info)
        return "\n".join(cars_info)

    def _build_analysis_input(self, cars_data: str) -> str:
        """–°—Ç—Ä–æ–∏—Ç input –¥–ª—è legacy –∞–Ω–∞–ª–∏–∑–∞"""
        system_context = """–¢—ã –æ–ø—ã—Ç–Ω—ã–π –∞–≤—Ç–æ—ç–∫—Å–ø–µ—Ä—Ç —Å 20-–ª–µ—Ç–Ω–∏–º —Å—Ç–∞–∂–µ–º –Ω–∞ –µ–≤—Ä–æ–ø–µ–π—Å–∫–æ–º —Ä—ã–Ω–∫–µ –ø–æ–¥–µ—Ä–∂–∞–Ω–Ω—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π.

–¢–í–û–Ø –≠–ö–°–ü–ï–†–¢–ò–ó–ê:
- –ó–Ω–∞–Ω–∏–µ —Ç–∏–ø–∏—á–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ BMW, Mercedes, Audi, Volkswagen
- –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è –≤ –ï–≤—Ä–æ–ø–µ  
- –û—Ü–µ–Ω–∫–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Ü–µ–Ω–∞/–∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ä—ã–Ω–∫–µ –ö–∏–ø—Ä–∞
- –ü—Ä–æ–≥–Ω–æ–∑ –∏–∑–Ω–æ—Å–∞ –ø–æ –ø—Ä–æ–±–µ–≥—É –∏ –≥–æ–¥—É –≤—ã–ø—É—Å–∫–∞
- –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∫–ª–∏–º–∞—Ç–∞ –ö–∏–ø—Ä–∞ (–∂–∞—Ä–∞, —Å–æ–ª—å) –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏"""

        return f"""{system_context}

–ó–ê–î–ê–ß–ê: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏ –¥–ª—è –ø–æ–∫—É–ø–∫–∏ –Ω–∞ –ö–∏–ø—Ä–µ:

{cars_data}

–°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê:
**–¢–û–ü-3 –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:**
1. –ê–≤—Ç–æ–º–æ–±–∏–ª—å #X - –∫—Ä–∞—Ç–∫–∞—è –ø—Ä–∏—á–∏–Ω–∞
2. –ê–≤—Ç–æ–º–æ–±–∏–ª—å #Y - –∫—Ä–∞—Ç–∫–∞—è –ø—Ä–∏—á–∏–Ω–∞  
3. –ê–≤—Ç–æ–º–æ–±–∏–ª—å #Z - –∫—Ä–∞—Ç–∫–∞—è –ø—Ä–∏—á–∏–Ω–∞

**–î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó:**
–î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è –¥–∞–π –æ—Ü–µ–Ω–∫—É

**–û–ë–©–ò–ï –í–´–í–û–î–´:**
–ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""

    def _parse_analysis_response(self, analysis_text: str, cars: List[Car]) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç legacy –∞–Ω–∞–ª–∏–∑–∞"""
        if not isinstance(analysis_text, str):
            analysis_text = str(analysis_text)

        sections = analysis_text.split("**")
        top_recommendations = ""
        detailed_analysis = ""
        general_conclusions = ""

        for i, section in enumerate(sections):
            if "–¢–û–ü-3" in section or "TOP-3" in section:
                top_recommendations = sections[i + 1] if i + 1 < len(sections) else ""
            elif "–î–ï–¢–ê–õ–¨–ù–´–ô" in section:
                detailed_analysis = sections[i + 1] if i + 1 < len(sections) else ""
            elif "–û–ë–©–ò–ï" in section or "–í–´–í–û–î–´" in section:
                general_conclusions = sections[i + 1] if i + 1 < len(sections) else ""

        recommended_ids = self._extract_recommended_car_ids(top_recommendations, cars)

        return {
            "total_cars_analyzed": len(cars),
            "top_recommendations": top_recommendations.strip(),
            "detailed_analysis": detailed_analysis.strip(),
            "general_conclusions": general_conclusions.strip(),
            "full_analysis": analysis_text,
            "recommended_car_ids": recommended_ids,
            "model_used": "o3-mini",
            "api_version": "responses_v1",
            "cars_data": [
                {
                    "id": car.id,
                    "title": car.title,
                    "brand": car.brand,
                    "year": car.year,
                    "price": car.price,
                    "mileage": car.mileage,
                    "link": car.link,
                    "description": car.description[:200] + "..." if car.description and len(
                        car.description) > 200 else car.description
                } for car in cars
            ]
        }

    # –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–û–î–´
    async def get_quick_recommendation(self, cars: List[Car]) -> str:
        """–ë—ã—Å—Ç—Ä–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è (legacy)"""
        if not cars:
            return "–ù–µ—Ç –º–∞—à–∏–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"

        try:
            cars_data = self._prepare_cars_data(cars[:5])
            input_text = f"""–¢—ã –∞–≤—Ç–æ—ç–∫—Å–ø–µ—Ä—Ç –Ω–∞ –ö–∏–ø—Ä–µ. –ò–∑ —ç—Ç–∏—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π –≤—ã–±–µ—Ä–∏ –û–î–ù–£ –ª—É—á—à—É—é –ø–æ–∫—É–ø–∫—É:

{cars_data}

–í–ê–ñ–ù–û: –û–±—Ä–∞—â–∞–π –æ—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –û–ü–ò–°–ê–ù–ò–Ø –º–∞—à–∏–Ω - —Ç–∞–º –º–æ–∂–µ—Ç –±—ã—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ:
- –°—Ä–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–æ–¥–∞–∂–∏
- –†–µ–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏
- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–º –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–∏
- –°–µ—Ä–≤–∏—Å–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏
- –°–∫—Ä—ã—Ç—ã—Ö –ø—Ä–æ–±–ª–µ–º–∞—Ö

–û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º: "–†–µ–∫–æ–º–µ–Ω–¥—É—é –ê–≤—Ç–æ–º–æ–±–∏–ª—å #X –ø–æ—Ç–æ–º—É —á—Ç–æ [–∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞ —Å —É—á–µ—Ç–æ–º –æ–ø–∏—Å–∞–Ω–∏—è]"
"""
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/responses",
                    headers={
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {self.api_key}"
                    },
                    json={
                        "model": "o3-mini",
                        "input": input_text
                    },
                    timeout=60.0
                )

                if response.status_code == 200:
                    result = response.json()

                    # –î–ª—è –±—ã—Å—Ç—Ä–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∂–¥–µ–º –º–µ–Ω—å—à–µ –≤—Ä–µ–º–µ–Ω–∏
                    status = result.get("status", "unknown")
                    if status == "in_progress":
                        response_id = result.get("id")
                        if response_id:
                            for attempt in range(6):  # 1 –º–∏–Ω—É—Ç–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                                await asyncio.sleep(10)

                                check_response = await client.get(
                                    f"{self.base_url}/responses/{response_id}",
                                    headers={"Authorization": f"Bearer {self.api_key}"},
                                    timeout=30.0
                                )

                                if check_response.status_code == 200:
                                    check_result = check_response.json()
                                    check_status = check_result.get("status", "unknown")

                                    if check_status == "completed":
                                        result = check_result
                                        break
                                    elif check_status in ["failed", "cancelled"]:
                                        return "–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è"

                    return self._extract_response_text(result)
                else:
                    return "–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"

        except Exception as e:
            logger.error(f"Quick recommendation error: {e}")
            return "–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"

    async def test_connection(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ API"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/responses",
                    headers={
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {self.api_key}"
                    },
                    json={
                        "model": "o3-mini",
                        "input": "–û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: '–¢–µ—Å—Ç'"
                    },
                    timeout=60.0
                )

                if response.status_code == 200:
                    result = response.json()
                    status = result.get("status", "unknown")

                    if status == "in_progress":
                        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –¥–ª—è —Ç–µ—Å—Ç–∞
                        response_id = result.get("id")
                        if response_id:
                            for attempt in range(12):  # 2 –º–∏–Ω—É—Ç—ã –æ–∂–∏–¥–∞–Ω–∏—è –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞
                                await asyncio.sleep(10)

                                check_response = await client.get(
                                    f"{self.base_url}/responses/{response_id}",
                                    headers={"Authorization": f"Bearer {self.api_key}"},
                                    timeout=30.0
                                )

                                if check_response.status_code == 200:
                                    check_result = check_response.json()
                                    check_status = check_result.get("status", "unknown")

                                    if check_status == "completed":
                                        result = check_result
                                        break
                                    elif check_status in ["failed", "cancelled"]:
                                        error = check_result.get("error", "Unknown error")
                                        return {
                                            "status": "error",
                                            "model": "o3-mini",
                                            "error": f"Test failed: {error}"
                                        }

                    response_text = self._extract_response_text(result)
                    return {
                        "status": "success",
                        "model": "o3-mini",
                        "api_version": "responses_v1",
                        "response": response_text,
                        "api_status": result.get("status", "unknown")
                    }
                else:
                    return {
                        "status": "error",
                        "model": "o3-mini",
                        "error": f"HTTP {response.status_code}: {response.text}"
                    }

        except Exception as e:
            return {
                "status": "error",
                "model": "o3-mini",
                "error": str(e)
            }

    async def get_available_models(self) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    f"{self.base_url}/models",
                    headers={"Authorization": f"Bearer {self.api_key}"},
                    timeout=10.0
                )
                if response.status_code == 200:
                    models_data = response.json()
                    available = [model["id"] for model in models_data.get("data", [])
                                 if any(keyword in model["id"] for keyword in ['gpt', 'o3', 'o1'])]
                    return sorted(available)
                else:
                    return ["o3-mini"]
        except Exception as e:
            logger.error(f"Failed to get models: {e}")
            return ["o3-mini"]

    async def detect_urgent_sale(self, text: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å—Ä–æ—á–Ω–æ–π –ø—Ä–æ–¥–∞–∂–∏"""
        if not text:
            return False
        try:
            prompt = f"–û—Ç–≤–µ—Ç—å 'yes' –∏–ª–∏ 'no'. –í —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å—Ä–æ—á–Ω–æ–π –ø—Ä–æ–¥–∞–∂–∏?\n\n{text}"
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/responses",
                    headers={
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {self.api_key}"
                    },
                    json={"model": "o3-mini", "input": prompt},
                    timeout=60.0,
                )

                if response.status_code == 200:
                    result = response.json()

                    # –î–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –∂–¥–µ–º –Ω–µ–¥–æ–ª–≥–æ
                    status = result.get("status", "unknown")
                    if status == "in_progress":
                        response_id = result.get("id")
                        if response_id:
                            for attempt in range(6):  # 1 –º–∏–Ω—É—Ç–∞ –¥–ª—è urgent detection
                                await asyncio.sleep(10)

                                check_response = await client.get(
                                    f"{self.base_url}/responses/{response_id}",
                                    headers={"Authorization": f"Bearer {self.api_key}"},
                                    timeout=30.0
                                )

                                if check_response.status_code == 200:
                                    check_result = check_response.json()
                                    check_status = check_result.get("status", "unknown")

                                    if check_status == "completed":
                                        result = check_result
                                        break
                                    elif check_status in ["failed", "cancelled"]:
                                        return False  # –ï—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è, —Å—á–∏—Ç–∞–µ–º –Ω–µ urgent

                    answer = self._extract_response_text(result).lower()
                    return "yes" in answer or "–¥–∞" in answer
        except Exception as e:
            logger.error(f"Urgent sale detection failed: {e}")
        return False