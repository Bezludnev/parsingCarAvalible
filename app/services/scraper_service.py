# app/services/scraper_service.py - –û–ë–ù–û–í–õ–ï–ù–ù–´–ô —Å –ø–∞—Ä—Å–∏–Ω–≥–æ–º –¥–µ—Ç–∞–ª–µ–π
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import re
import time
import json
from typing import List, Dict, Optional
from app.config import settings
from app.schemas.car import CarCreate, CarDetailUpdate
import logging

logger = logging.getLogger(__name__)


class ScraperService:
    def __init__(self):
        self.options = Options()
        self.options.add_argument('--headless')
        self.options.add_argument('--disable-gpu')
        self.options.add_argument('--no-sandbox')
        self.options.add_argument('--disable-dev-shm-usage')

    def _create_driver(self) -> webdriver.Chrome:
        return webdriver.Chrome(options=self.options)

    def _parse_car_data(self, ad, filter_config: Dict) -> Optional[CarCreate]:
        """–ü–∞—Ä—Å–∏—Ç –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        # Title –∏ link
        title_tag = ad.find("a", class_="advert__content-title")
        if not title_tag:
            return None

        title = title_tag.text.strip()
        link = "https://www.bazaraki.com" + title_tag.get('href', '')

        # Price
        price_tag = ad.find("a", class_="advert__content-price")
        price = price_tag.text.strip().replace("\n", " ") if price_tag else "–Ω–µ—Ç —Ü–µ–Ω—ã"

        # Parse features
        features_tag = ad.find("div", class_="advert__content-features")
        features = []
        mileage = None
        year = None

        if features_tag:
            for f in features_tag.find_all("div", class_="advert__content-feature"):
                text = f.text.strip()
                features.append(text)

                # Parse mileage
                mileage_match = re.search(r'([\d,. ]+)\s*km', text.lower())
                if mileage_match:
                    mileage_str = mileage_match.group(1).replace(',', '').replace(' ', '')
                    try:
                        mileage = int(mileage_str)
                    except:
                        pass

                # Parse year
                year_match = re.search(r'(19\d{2}|20\d{2})', text)
                if year_match:
                    try:
                        year = int(year_match.group(1))
                    except:
                        pass

        # Parse year from title if not found
        if year is None:
            title_year_match = re.search(r'(19\d{2}|20\d{2})', title)
            if title_year_match:
                try:
                    year = int(title_year_match.group(1))
                except:
                    pass

        # Date and place
        hint_tag = ad.find("div", class_="advert__content-hint")
        date_posted, place = "–Ω–µ—Ç –¥–∞—Ç—ã", "–Ω–µ—Ç –≥–æ—Ä–æ–¥–∞"

        if hint_tag:
            date_tag = hint_tag.find("div", class_="advert__content-date")
            if date_tag:
                date_posted = date_tag.text.strip()

            place_tag = hint_tag.find("div", class_="advert__content-place")
            if place_tag:
                place = place_tag.text.strip()

        # Apply filters
        if year and year < filter_config.get("min_year", 0):
            return None

        if mileage and mileage > filter_config.get("max_mileage", float('inf')):
            return None

        return CarCreate(
            title=title,
            link=link,
            price=price,
            brand=filter_config["brand"],
            year=year,
            mileage=mileage,
            features=' | '.join(features) if features else "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
            date_posted=date_posted,
            place=place,
            filter_name=filter_config.get("filter_name", "unknown"),
            details_parsed=False  # –ü–æ–∫–∞ –¥–µ—Ç–∞–ª–∏ –Ω–µ –ø–∞—Ä—Å–∏–ª–∏—Å—å
        )

    def parse_car_details(self, driver: webdriver.Chrome, car_url: str) -> CarDetailUpdate:
        """üîç –ü–∞—Ä—Å–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –∞–≤—Ç–æ–º–æ–±–∏–ª—è"""
        try:
            logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ –¥–µ—Ç–∞–ª–µ–π: {car_url}")
            driver.get(car_url)
            time.sleep(3)  # –î–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å—Å—è

            soup = BeautifulSoup(driver.page_source, "html.parser")
            details = {}
            extra_chars = {}

            # === –ü–ê–†–°–ò–ù–ì –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö –ò–ó –¢–ê–ë–õ–ò–¶–´ ===
            characteristics_div = soup.find("div", class_="announcement-characteristics clearfix")
            if characteristics_div:
                ul = characteristics_div.find("ul", class_="chars-column")
                if ul:
                    for li in ul.find_all("li"):
                        key_span = li.find("span", class_="key-chars")
                        value_tag = li.find("a", class_="value-chars") or li.find("span", class_="value-chars")

                        if key_span and value_tag:
                            key = key_span.text.strip(': \n').lower()
                            value = value_tag.text.strip()

                            # –ú–∞–ø–ø–∏–Ω–≥ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ–ª–µ–π
                            field_mapping = {
                                'mot till': 'mot_till',
                                'colour': 'colour',
                                'color': 'colour',
                                'gearbox': 'gearbox',
                                'fuel type': 'fuel_type',
                                'engine size': 'engine_size',
                                'doors': 'doors',
                                'seats': 'seats',
                                'condition': 'condition',
                                'previous owners': 'previous_owners',
                                'registration': 'registration',
                                'import duty paid': 'import_duty_paid',
                                'roadworthy certificate': 'roadworthy_certificate'
                            }

                            mapped_field = field_mapping.get(key)
                            if mapped_field:
                                details[mapped_field] = value
                            else:
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ extra_characteristics
                                extra_chars[key] = value

            # === –ü–ê–†–°–ò–ù–ì –û–ü–ò–°–ê–ù–ò–Ø ===
            description = ""

            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è
            description_selectors = [
                "div.js-description",
                "div[itemprop='description']",
                "div.announcement-description",
                "div.description-text"
            ]

            for selector in description_selectors:
                desc_div = soup.select_one(selector)
                if desc_div:
                    description = desc_div.get_text(strip=True)
                    break

            # === –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –¢–ò–ü–ê –ü–†–û–î–ê–í–¶–ê ===
            seller_type = "unknown"

            # –ò—â–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–∏–ª–µ—Ä–∞
            dealer_indicators = soup.find_all(text=re.compile(r'dealer|–¥–∏–ª–µ—Ä|garage|–∞–≤—Ç–æ—Å–∞–ª–æ–Ω', re.I))
            if dealer_indicators:
                seller_type = "dealer"
            else:
                seller_type = "private"

            # === –ö–û–ù–¢–ê–ö–¢–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø ===
            contact_info = ""

            contact_div = soup.find("div", class_="announcement-contact")
            if contact_div:
                contact_info = contact_div.get_text(strip=True)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±—ä–µ–∫—Ç –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            detail_update = CarDetailUpdate(
                mot_till=details.get('mot_till'),
                colour=details.get('colour'),
                gearbox=details.get('gearbox'),
                fuel_type=details.get('fuel_type'),
                engine_size=details.get('engine_size'),
                doors=details.get('doors'),
                seats=details.get('seats'),
                condition=details.get('condition'),
                previous_owners=details.get('previous_owners'),
                registration=details.get('registration'),
                import_duty_paid=details.get('import_duty_paid'),
                roadworthy_certificate=details.get('roadworthy_certificate'),
                description=description if description else None,
                seller_type=seller_type,
                contact_info=contact_info if contact_info else None,
                extra_characteristics=json.dumps(extra_chars, ensure_ascii=False) if extra_chars else None,
                details_parsed=True
            )

            logger.info(
                f"‚úÖ –î–µ—Ç–∞–ª–∏ —É—Å–ø–µ—à–Ω–æ –ø–∞—Ä—Å–∏—Ä–æ–≤–∞–Ω—ã: {len(details)} –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–æ–ª–µ–π, {len(extra_chars)} –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö")
            return detail_update

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–µ—Ç–∞–ª–µ–π {car_url}: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç —Å —Ñ–ª–∞–≥–æ–º –æ—à–∏–±–∫–∏
            return CarDetailUpdate(
                details_parsed=False,
                description=f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}"
            )

    async def scrape_cars(self, filter_name: str) -> List[CarCreate]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        filter_config = settings.car_filters.get(filter_name)
        if not filter_config:
            return []

        filter_config["filter_name"] = filter_name

        driver = self._create_driver()
        try:
            driver.get(filter_config["url"])
            time.sleep(5)

            html = driver.page_source
            soup = BeautifulSoup(html, "html.parser")
            ads = soup.find_all("div", class_="advert js-item-listing")

            cars = []
            for ad in ads:
                car_data = self._parse_car_data(ad, filter_config)
                if car_data:
                    cars.append(car_data)

            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(cars)} –º–∞—à–∏–Ω –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞ {filter_name}")
            return cars

        finally:
            driver.quit()

    async def scrape_car_details_batch(self, car_links: List[str], batch_size: int = 5) -> List[CarDetailUpdate]:
        """üîÑ –ü–∞–∫–µ—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–µ—Ç–∞–ª–µ–π –¥–ª—è —Å–ø–∏—Å–∫–∞ –º–∞—à–∏–Ω"""

        if not car_links:
            return []

        results = []
        driver = self._create_driver()

        try:
            logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –ø–∞–∫–µ—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–µ—Ç–∞–ª–µ–π –¥–ª—è {len(car_links)} –º–∞—à–∏–Ω")

            for i, link in enumerate(car_links):
                try:
                    detail_update = self.parse_car_details(driver, link)
                    results.append(detail_update)

                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    if i < len(car_links) - 1:
                        time.sleep(2)

                    # –ü—Ä–æ–≥—Ä–µ—Å—Å
                    if (i + 1) % 5 == 0:
                        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ –¥–µ—Ç–∞–ª–µ–π: {i + 1}/{len(car_links)}")

                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–µ—Ç–∞–ª–µ–π –¥–ª—è {link}: {e}")
                    results.append(CarDetailUpdate(details_parsed=False))

            logger.info(f"‚úÖ –ü–∞–∫–µ—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            return results

        finally:
            driver.quit()

    async def scrape_cars_with_details(self, filter_name: str, parse_details: bool = True) -> List[CarCreate]:
        """üöÄ –ü–æ–ª–Ω—ã–π —Å–∫—Ä–∞–ø–∏–Ω–≥: –æ—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è + –¥–µ—Ç–∞–ª–∏"""

        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        cars = await self.scrape_cars(filter_name)

        if not cars or not parse_details:
            return cars

        # –ó–∞—Ç–µ–º –ø–∞—Ä—Å–∏–º –¥–µ—Ç–∞–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –º–∞—à–∏–Ω—ã
        logger.info(f"–ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –¥–µ—Ç–∞–ª–µ–π –¥–ª—è {len(cars)} –º–∞—à–∏–Ω...")

        driver = self._create_driver()

        try:
            for i, car in enumerate(cars):
                try:
                    detail_update = self.parse_car_details(driver, car.link)

                    # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –æ–±—ä–µ–∫—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                    for field, value in detail_update.dict(exclude_unset=True).items():
                        if hasattr(car, field) and value is not None:
                            setattr(car, field, value)

                    time.sleep(2)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏

                    if (i + 1) % 3 == 0:
                        logger.info(f"–î–µ—Ç–∞–ª–∏ –ø–∞—Ä—Å–∏—Ä–æ–≤–∞–Ω—ã: {i + 1}/{len(cars)}")

                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–µ—Ç–∞–ª–µ–π –¥–ª—è {car.title}: {e}")
                    # –ü–æ–º–µ—á–∞–µ–º —á—Ç–æ –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è
                    car.details_parsed = False

            logger.info(f"‚úÖ –ü–æ–ª–Ω—ã–π —Å–∫—Ä–∞–ø–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è {filter_name}")
            return cars

        finally:
            driver.quit()