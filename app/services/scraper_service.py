# app/services/scraper_service.py - –û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø —Å urgent –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import re
import asyncio
from typing import List, Dict, Optional
from app.config import settings
from app.schemas.car import CarCreate
import httpx
import logging

logger = logging.getLogger(__name__)


class ScraperService:
    def __init__(self):
        self.options = Options()
        self.options.add_argument('--headless')
        self.options.add_argument('--disable-gpu')
        self.options.add_argument('--no-sandbox')
        self.options.add_argument('--disable-dev-shm-usage')

    def _fetch_description(self, link: str) -> Optional[str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ"""
        try:
            with httpx.Client(timeout=10.0) as client:
                resp = client.get(link)
                if resp.status_code != 200:
                    return None
                soup = BeautifulSoup(resp.text, 'html.parser')
                desc_div = soup.find('div', class_='js-description')
                if desc_div:
                    paragraphs = [p.get_text(' ', strip=True) for p in desc_div.find_all('p')]
                    return ' '.join(paragraphs)
        except Exception:
            return None
        return None

    def _create_driver(self) -> webdriver.Chrome:
        """Create Chrome driver using path from settings"""
        service = Service(executable_path=settings.chromedriver_path)
        return webdriver.Chrome(service=service, options=self.options)

    def _has_urgent_keywords(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ urgent –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ"""
        if not text:
            return False

        urgent_keywords = [
            '—Å—Ä–æ—á–Ω–æ', 'urgent', '–±—ã—Å—Ç—Ä–æ', 'asap', 'must sell', 'price drop',
            'reduced', 'negotiable', 'open to offers', '—Ç–æ—Ä–≥', '–æ–±–º–µ–Ω',
            '–≤—ã–≥–æ–¥–Ω–æ', '–Ω–µ–¥–æ—Ä–æ–≥–æ', '–¥–µ—à–µ–≤–æ', '—Å–Ω–∏–∂–µ–Ω–∞ —Ü–µ–Ω–∞', '—É–º–µ—Å—Ç–µ–Ω —Ç–æ—Ä–≥'
        ]

        text_lower = text.lower()
        return any(keyword in text_lower for keyword in urgent_keywords)

    def _parse_car_data(self, ad, filter_config: Dict) -> Optional[CarCreate]:
        # Title –∏ link
        title_tag = ad.find("a", class_="advert__content-title")
        if not title_tag:
            return None

        title = title_tag.text.strip()
        link = "https://www.bazaraki.com" + title_tag.get('href', '')

        # Price
        price_tag = ad.find("a", class_="advert__content-price")
        price = price_tag.text.strip().replace("\n", " ") if price_tag else "–Ω–µ—Ç —Ü–µ–Ω—ã"

        # Parse features
        features_tag = ad.find("div", class_="advert__content-features")
        features = []
        mileage = None
        year = None

        if features_tag:
            for f in features_tag.find_all("div", class_="advert__content-feature"):
                text = f.text.strip()
                features.append(text)

                # Parse mileage
                mileage_match = re.search(r'([\d,. ]+)\s*km', text.lower())
                if mileage_match:
                    mileage_str = mileage_match.group(1).replace(',', '').replace(' ', '')
                    try:
                        mileage = int(mileage_str)
                    except:
                        pass

                # Parse year
                year_match = re.search(r'(19\d{2}|20\d{2})', text)
                if year_match:
                    try:
                        year = int(year_match.group(1))
                    except:
                        pass

        # Parse year from title if not found
        if year is None:
            title_year_match = re.search(r'(19\d{2}|20\d{2})', title)
            if title_year_match:
                try:
                    year = int(title_year_match.group(1))
                except:
                    pass

        # Date and place
        hint_tag = ad.find("div", class_="advert__content-hint")
        date_posted, place = "–Ω–µ—Ç –¥–∞—Ç—ã", "–Ω–µ—Ç –≥–æ—Ä–æ–¥–∞"

        if hint_tag:
            date_tag = hint_tag.find("div", class_="advert__content-date")
            if date_tag:
                date_posted = date_tag.text.strip()

            place_tag = hint_tag.find("div", class_="advert__content-place")
            if place_tag:
                place = place_tag.text.strip()

        # Description
        desc_tag = ad.find("div", class_="advert__description")
        if not desc_tag:
            desc_tag = ad.find("div", class_="advert__content-description")
        description = desc_tag.text.strip() if desc_tag else None
        if not description:
            description = self._fetch_description(link)

        # üî• URGENT MODE LOGIC - –±–æ–ª–µ–µ –º—è–≥–∫–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã
        is_urgent_mode = filter_config.get("urgent_mode", False)

        if is_urgent_mode:
            # –í urgent —Ä–µ–∂–∏–º–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            has_urgent_text = self._has_urgent_keywords(title) or self._has_urgent_keywords(description)

            # –ë–æ–ª–µ–µ –º—è–≥–∫–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª—è urgent
            if year and year < filter_config.get("min_year", 0):
                # –í urgent —Ä–µ–∂–∏–º–µ –ø–æ–∑–≤–æ–ª—è–µ–º –º–∞—à–∏–Ω—ã –Ω–∞ 2 –≥–æ–¥–∞ —Å—Ç–∞—Ä—à–µ
                if year < (filter_config.get("min_year", 0) - 2):
                    return None

            if mileage and mileage > filter_config.get("max_mileage", float('inf')):
                # –í urgent —Ä–µ–∂–∏–º–µ –ø–æ–∑–≤–æ–ª—è–µ–º +50k –ø—Ä–æ–±–µ–≥–∞ –µ—Å–ª–∏ –µ—Å—Ç—å urgent keywords
                max_allowed = filter_config.get("max_mileage", float('inf'))
                if has_urgent_text:
                    max_allowed += 50000  # –ë–æ–Ω—É—Å –¥–ª—è urgent –æ–±—ä—è–≤–ª–µ–Ω–∏–π
                if mileage > max_allowed:
                    return None

            logger.info(f"üî• Urgent —Ä–µ–∂–∏–º: {filter_config.get('filter_name')} - –Ω–∞–π–¥–µ–Ω–∞ –º–∞—à–∏–Ω–∞"
                        f" {'(URGENT keywords!)' if has_urgent_text else ''}")
        else:
            # –û–±—ã—á–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            if year and year < filter_config.get("min_year", 0):
                return None

            if mileage and mileage > filter_config.get("max_mileage", float('inf')):
                return None

        return CarCreate(
            title=title,
            link=link,
            price=price,
            brand=filter_config["brand"],
            year=year,
            mileage=mileage,
            features=' | '.join(features) if features else "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
            description=description,
            date_posted=date_posted,
            place=place,
            filter_name=filter_config.get("filter_name", "unknown")
        )

    def _scrape_cars_sync(self, filter_config: Dict) -> List[CarCreate]:
        """Synchronous scraping logic executed in a thread"""
        is_urgent = filter_config.get("urgent_mode", False)
        filter_name = filter_config.get("filter_name", "unknown")

        logger.info(f"üåê –ù–∞—á–∏–Ω–∞–µ–º —Å–∫—Ä–∞–ø–∏–Ω–≥: {filter_name} "
                    f"{'(URGENT —Ä–µ–∂–∏–º)' if is_urgent else '(–æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º)'}")

        driver = self._create_driver()
        try:
            driver.get(filter_config["url"])
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located(
                    (By.CSS_SELECTOR, "div.advert.js-item-listing")
                )
            )

            html = driver.page_source
            soup = BeautifulSoup(html, "html.parser")
            ads = soup.find_all("div", class_="advert js-item-listing")

            logger.info(f"üìÑ –ù–∞–π–¥–µ–Ω–æ {len(ads)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –¥–ª—è {filter_name}")

            cars = []
            for ad in ads:
                car_data = self._parse_car_data(ad, filter_config)
                if car_data:
                    cars.append(car_data)

            logger.info(f"‚úÖ –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ: {len(cars)} –º–∞—à–∏–Ω –¥–ª—è {filter_name}")
            return cars

        finally:
            driver.quit()

    async def scrape_cars(self, filter_name: str) -> List[CarCreate]:
        """Public async method that offloads work to a thread"""
        filter_config = settings.car_filters.get(filter_name)
        if not filter_config:
            logger.warning(f"‚ùå –§–∏–ª—å—Ç—Ä {filter_name} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
            return []

        filter_config["filter_name"] = filter_name

        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, self._scrape_cars_sync, filter_config)


    async def get_available_filters(self) -> Dict[str, Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ä–µ–∂–∏–º–µ"""
        filters_info = {}

        for name, config in settings.car_filters.items():
            filters_info[name] = {
                "brand": config["brand"],
                "min_year": config["min_year"],
                "max_mileage": config["max_mileage"],
                "urgent_mode": config.get("urgent_mode", False),
                "price_range": self._extract_price_range(config["url"])
            }

        return filters_info

    def _extract_price_range(self, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–µ–Ω–æ–≤–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω –∏–∑ URL"""
        try:
            price_min_match = re.search(r'price_min=(\d+)', url)
            price_max_match = re.search(r'price_max=(\d+)', url)

            if price_min_match and price_max_match:
                min_price = int(price_min_match.group(1))
                max_price = int(price_max_match.group(1))
                return f"‚Ç¨{min_price:,} - ‚Ç¨{max_price:,}"
        except:
            pass
        return "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
